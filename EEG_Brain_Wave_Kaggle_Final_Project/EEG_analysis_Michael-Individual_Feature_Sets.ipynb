{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from pandas import *\n",
    "\n",
    "# SK-learn libraries.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "\n",
    "# scipy\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Merge The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1438813062.47 Merging...\n",
      "1438813062.47 C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train\\subj1_series1_data.csv\n",
      "1438813063.17 C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train\\subj1_series2_data.csv\n",
      "Merge Complete: 2.55599999428 total seconds\n",
      "1438813065.04 Merging...\n",
      "1438813065.04 C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train\\subj1_series1_events.csv\n",
      "1438813065.23 C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train\\subj1_series2_events.csv\n",
      "Merge Complete: 0.526000022888 total seconds\n",
      "1438813065.57 Merging...\n",
      "1438813065.57 C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train\\subj1_series3_data.csv\n",
      "Merge Complete: 1.09799981117 total seconds\n",
      "1438813066.67 Merging...\n",
      "1438813066.67 C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train\\subj1_series3_events.csv\n",
      "Merge Complete: 0.238999843597 total seconds\n"
     ]
    }
   ],
   "source": [
    "#Remove the channels we don't want \n",
    "def Remove_Channels(df):\n",
    "    df.drop(df.columns[[15,16,20,21,22,25,26,27,28,29,30,31,32]], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "path =r'C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train'\n",
    "train_data_filenames = glob.glob(path + \"/subj1_series[1-2]*data.csv\") #load only subject 1, series 1-3\n",
    "list_ = []\n",
    "Train_Array_Lengths = []\n",
    "Start_Time = time.time()\n",
    "print time.time(), \"Merging...\"\n",
    "\n",
    "for file_ in train_data_filenames:\n",
    "    print time.time(), file_\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(Remove_Channels(df))\n",
    "    Train_Array_Lengths.append(len(df))\n",
    "train_data = pd.concat(list_)\n",
    "\n",
    "print \"Merge Complete:\", time.time()-Start_Time, \"total seconds\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#now with event data\n",
    "path =r'C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train'\n",
    "train_event_filenames = glob.glob(path + \"/subj1_series[1-2]*events.csv\") #load only subject 1, series 1-3\n",
    "list_ = []\n",
    "\n",
    "Start_Time = time.time()\n",
    "print time.time(), \"Merging...\"\n",
    "\n",
    "for file_ in train_event_filenames:\n",
    "    print time.time(), file_\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "train_events = pd.concat(list_)\n",
    "\n",
    "print \"Merge Complete:\", time.time()-Start_Time, \"total seconds\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#do the same thing and now get your testing data\n",
    "test_data_filenames = glob.glob(path + \"/subj1_series3*data.csv\") #load only subject 1, series 1-3\n",
    "list_ = []\n",
    "Test_Array_Lengths = []\n",
    "Start_Time = time.time()\n",
    "print time.time(), \"Merging...\"\n",
    "\n",
    "for file_ in test_data_filenames:\n",
    "    print time.time(), file_\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(Remove_Channels(df))\n",
    "    Test_Array_Lengths.append(len(df))\n",
    "test_data = pd.concat(list_)\n",
    "\n",
    "print \"Merge Complete:\", time.time()-Start_Time, \"total seconds\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#now with event data\n",
    "path =r'C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train'\n",
    "test_event_filenames = glob.glob(path + \"/subj1_series3*events.csv\") #load only subject 1, series 1-3\n",
    "list_ = []\n",
    "\n",
    "Start_Time = time.time()\n",
    "print time.time(), \"Merging...\"\n",
    "\n",
    "for file_ in test_event_filenames:\n",
    "    print time.time(), file_\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "test_events = pd.concat(list_)\n",
    "\n",
    "print \"Merge Complete:\", time.time()-Start_Time, \"total seconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate the data into the 6 events and into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Labels_HandStart =  train_events['HandStart'].to_sparse(fill_value=0)\n",
    "Train_Labels_FirstDigitTouch =  train_events['FirstDigitTouch'].to_sparse(fill_value=0)\n",
    "Train_Labels_BothStartLoadPhase =  train_events['BothStartLoadPhase'].to_sparse(fill_value=0)\n",
    "Train_Labels_LiftOff =  train_events['LiftOff'].to_sparse(fill_value=0)\n",
    "Train_Labels_Replace =  train_events['Replace'].to_sparse(fill_value=0)\n",
    "Train_Labels_BothReleased =  train_events['BothReleased'].to_sparse(fill_value=0)\n",
    "# Train_Labels_Combined = train_events.HandStart.map(str) + ',' + train_events.FirstDigitTouch.map(str) + ',' + train_events.BothStartLoadPhase.map(str) + ',' + train_events.LiftOff.map(str) + ',' + train_events.Replace.map(str) + ',' + train_events.BothReleased.map(str)\n",
    "\n",
    "\n",
    "Train_Data = train_data.iloc[0:,1:] # select only column data\n",
    "\n",
    "\n",
    "Test_Labels_HandStart =  test_events['HandStart'].to_sparse(fill_value=0)\n",
    "Test_Labels_FirstDigitTouch =  test_events['FirstDigitTouch'].to_sparse(fill_value=0)\n",
    "Test_Labels_BothStartLoadPhase =  test_events['BothStartLoadPhase'].to_sparse(fill_value=0)\n",
    "Test_Labels_LiftOff =  test_events['LiftOff'].to_sparse(fill_value=0)\n",
    "Test_Labels_Replace =  test_events['Replace'].to_sparse(fill_value=0)\n",
    "Test_Labels_BothReleased =  test_events['BothReleased'].to_sparse(fill_value=0)\n",
    "\n",
    "\n",
    "Test_Data = test_data.iloc[0:,1:] # select only data columns\n",
    "\n",
    "#delete what isn't needed anymore to save memory. \n",
    "del train_data\n",
    "del test_data\n",
    "del train_events\n",
    "del test_events\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#bin the time \n",
    "def Bin_Time(num_rows,num_bins):\n",
    "    Bin_Size = num_rows/num_bins\n",
    "    Bins = np.zeros(shape=(num_rows,num_bins))\n",
    "    Bin_Min = 0\n",
    "    Bin_Max = Bin_Size\n",
    "    for i in range(0,num_bins):\n",
    "        Bins[Bin_Min:Bin_Max,i] = 1\n",
    "        Bin_Min = Bin_Min + Bin_Size\n",
    "        Bin_Max = Bin_Max + Bin_Size\n",
    "    return Bins\n",
    "\n",
    "\n",
    "##filters borrowed from Nihar. \n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "#run PCA and return the number of PCs that explain the given amount of variance. \n",
    "def extractFeatures_PCA(Train_Data,Test_Data, PercentVarExplained):\n",
    "    pca = PCA()\n",
    "    pca.fit(Train_Data)  \n",
    "    \n",
    "    Explained_Variance_Ratios = pca.explained_variance_ratio_\n",
    "    for i in range(1,len(Explained_Variance_Ratios)):\n",
    "        if sum(Explained_Variance_Ratios[0:i]) >= PercentVarExplained:\n",
    "                   NumPCs = i + 1 #add 1 since numpy array ranges are not inclusive\n",
    "                   break\n",
    "    PCA_Projections = pca.transform(Train_Data)[:,0:NumPCs]\n",
    "    PCA_Projections_Test = pca.transform(Test_Data)[:,0:NumPCs]\n",
    "    return np.float32(PCA_Projections),np.float32(PCA_Projections_Test)\n",
    "\n",
    "\n",
    "\n",
    "#return rolling mean of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_mean(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_mean(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'mean' + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "\n",
    "#return rolling variance of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_var(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_var(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'var' + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "#return rolling min of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_min(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_min(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'min' + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "#return rolling max of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_max(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_max(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'max' + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "\n",
    "#return rolling skew of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_skew(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_skew(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'skew' + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "\n",
    "#return rolling skew of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_kurt(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_kurt(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'kurt' + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "\n",
    "#return rolling quantile of each column in a pandas dataframe with a given window and quantile. Returns df of same size. \n",
    "def df_rolling_quantile(df,window,quantile):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_quantile(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'Pct'+ quantile + \"_\" + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "#BE CAREFUL NOT TO SUPPLY TOO MANY COLUMNS TO THIS FUNCTION. Returns 2^N columns, where N = intitial columns. \n",
    "#return rolling pairwise correlation of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_corr(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        list_.append(pd.rolling_corr(df.iloc[0:,i],window,min_periods = 0))\n",
    "    return pd.concat(list_,1)\n",
    "\n",
    "\n",
    "\n",
    "#BE CAREFUL NOT TO SUPPLY TOO MANY COLUMNS TO THIS FUNCTION. Returns 2^N columns, where N = intitial columns. \n",
    "#return rolling pairwise correlation of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_cov(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        list_.append(rolling_cov(df.iloc[0:,i],window,min_periods = 0))\n",
    "    return pd.concat(list_,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Feature Creation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section takes rolling statistics for different windows of time for each column of the dataframe. It then does an RFE feature selection technique to keep only the top features for each rolling stat for each of the six labels. It then appends all of this together into a customized feature array for each of the six labels.  \n",
    "\n",
    "This took about 10 minutes on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculations With Window of 20 Complete:  13  Seconds\n",
      "Feature Concatenation with a Rolling Window of 20 Complete:  14  Seconds\n",
      "Calculations With Window of 100 Complete:  28  Seconds\n",
      "Feature Concatenation with a Rolling Window of 100 Complete:  28  Seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "HandStart_Test_Features = []\n",
    "FirstDigitTouch_Test_Features = []\n",
    "BothStartLoadPhase_Test_Features = []\n",
    "LiftOff_Test_Features = []\n",
    "Replace_Test_Features = []\n",
    "BothReleased_Test_Features = []\n",
    "\n",
    "HandStart_Train_Features = []\n",
    "FirstDigitTouch_Train_Features = []\n",
    "BothStartLoadPhase_Train_Features = []\n",
    "LiftOff_Train_Features = []\n",
    "Replace_Train_Features = []\n",
    "BothReleased_Train_Features = []\n",
    "\n",
    "Windows = [20, 100]\n",
    "Start_Time = time.time()\n",
    "for w in Windows:\n",
    "    Raw_Data_Rolling_Window = w\n",
    "    \n",
    "    \n",
    "    RawData_Rolling_Means_Train = df_rolling_mean(pd.DataFrame(Train_Data),Raw_Data_Rolling_Window)\n",
    "    RawData_Rolling_Var_Train = df_rolling_var(pd.DataFrame(Train_Data),Raw_Data_Rolling_Window)\n",
    "    RawData_Rolling_Skewness_Train = df_rolling_skew(pd.DataFrame(Train_Data),Raw_Data_Rolling_Window)\n",
    "    RawData_Rolling_Min_Train = df_rolling_min(pd.DataFrame(Train_Data),Raw_Data_Rolling_Window)\n",
    "    RawData_Rolling_Max_Train = df_rolling_max(pd.DataFrame(Train_Data),Raw_Data_Rolling_Window)\n",
    "\n",
    "\n",
    "    RawData_Rolling_Means_Test = df_rolling_mean(pd.DataFrame(Test_Data),Raw_Data_Rolling_Window)\n",
    "    RawData_Rolling_Var_Test = df_rolling_var(pd.DataFrame(Test_Data),Raw_Data_Rolling_Window)\n",
    "    RawData_Rolling_Skewness_Test = df_rolling_skew(pd.DataFrame(Test_Data),Raw_Data_Rolling_Window)\n",
    "    RawData_Rolling_Min_Test = df_rolling_min(pd.DataFrame(Test_Data),Raw_Data_Rolling_Window)\n",
    "    RawData_Rolling_Max_Test = df_rolling_max(pd.DataFrame(Test_Data),Raw_Data_Rolling_Window)\n",
    "\n",
    "    print \"Calculations With Window of\", w, \"Complete: \", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "    \n",
    "    #Append all the features to a feature set for each event. \n",
    "    HandStart_Train_Features.append(np.concatenate((RawData_Rolling_Means_Train,RawData_Rolling_Var_Train,RawData_Rolling_Skewness_Train,RawData_Rolling_Min_Train,RawData_Rolling_Max_Train),axis = 1))\n",
    "    HandStart_Test_Features.append(np.concatenate((RawData_Rolling_Means_Test,RawData_Rolling_Var_Test,RawData_Rolling_Skewness_Test,RawData_Rolling_Min_Test,RawData_Rolling_Max_Test),axis = 1))\n",
    "    \n",
    "    FirstDigitTouch_Train_Features.append(np.concatenate((RawData_Rolling_Means_Train,RawData_Rolling_Var_Train,RawData_Rolling_Skewness_Train,RawData_Rolling_Min_Train,RawData_Rolling_Max_Train),axis = 1))\n",
    "    FirstDigitTouch_Test_Features.append(np.concatenate((RawData_Rolling_Means_Test,RawData_Rolling_Var_Test,RawData_Rolling_Skewness_Test,RawData_Rolling_Min_Test,RawData_Rolling_Max_Test),axis = 1))\n",
    "    \n",
    "    BothStartLoadPhase_Train_Features.append(np.concatenate((RawData_Rolling_Means_Train,RawData_Rolling_Var_Train,RawData_Rolling_Skewness_Train,RawData_Rolling_Min_Train,RawData_Rolling_Max_Train),axis = 1))\n",
    "    BothStartLoadPhase_Test_Features.append(np.concatenate((RawData_Rolling_Means_Test,RawData_Rolling_Var_Test,RawData_Rolling_Skewness_Test,RawData_Rolling_Min_Test,RawData_Rolling_Max_Test),axis = 1))\n",
    "    \n",
    "    LiftOff_Train_Features.append(np.concatenate((RawData_Rolling_Means_Train,RawData_Rolling_Var_Train,RawData_Rolling_Skewness_Train,RawData_Rolling_Min_Train,RawData_Rolling_Max_Train),axis = 1))\n",
    "    LiftOff_Test_Features.append(np.concatenate((RawData_Rolling_Means_Test,RawData_Rolling_Var_Test,RawData_Rolling_Skewness_Test,RawData_Rolling_Min_Test,RawData_Rolling_Max_Test),axis = 1))\n",
    "    \n",
    "    Replace_Train_Features.append(np.concatenate((RawData_Rolling_Means_Train,RawData_Rolling_Var_Train,RawData_Rolling_Skewness_Train,RawData_Rolling_Min_Train,RawData_Rolling_Max_Train),axis = 1))\n",
    "    Replace_Test_Features.append(np.concatenate((RawData_Rolling_Means_Test,RawData_Rolling_Var_Test,RawData_Rolling_Skewness_Test,RawData_Rolling_Min_Test,RawData_Rolling_Max_Test),axis = 1))\n",
    "    \n",
    "    BothReleased_Train_Features.append(np.concatenate((RawData_Rolling_Means_Train,RawData_Rolling_Var_Train,RawData_Rolling_Skewness_Train,RawData_Rolling_Min_Train,RawData_Rolling_Max_Train),axis = 1))\n",
    "    BothReleased_Test_Features.append(np.concatenate((RawData_Rolling_Means_Test,RawData_Rolling_Var_Test,RawData_Rolling_Skewness_Test,RawData_Rolling_Min_Test,RawData_Rolling_Max_Test),axis = 1))\n",
    "    \n",
    "    print \"Feature Concatenation with a Rolling Window of\", w, \"Complete: \", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "#delete what isn't needed anymore to save memory. \n",
    "\n",
    "del RawData_Rolling_Means_Train\n",
    "del RawData_Rolling_Means_Test\n",
    "\n",
    "del RawData_Rolling_Var_Train\n",
    "del RawData_Rolling_Var_Test\n",
    "\n",
    "del RawData_Rolling_Skewness_Train\n",
    "del RawData_Rolling_Skewness_Test\n",
    "\n",
    "del RawData_Rolling_Min_Train\n",
    "del RawData_Rolling_Min_Test\n",
    "\n",
    "del RawData_Rolling_Max_Train\n",
    "del RawData_Rolling_Max_Test\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin the entire series into chunks of time. One feature per time bin. \n",
    "Then reduce the time bin feature set for each event with recursive feature elimination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Bin Creation Complete:  34  Seconds\n",
      "Time Bins Added to Feature Sets For Each Event:  70  Seconds\n"
     ]
    }
   ],
   "source": [
    "Initial_Num_Bins = 100\n",
    "\n",
    "Reduced_Number_Of_Bin = 10\n",
    "\n",
    "Reduction_Step = 10\n",
    "\n",
    "C_Value = 1\n",
    "penalty = 'l1'\n",
    "Convergence_tol = .1\n",
    "\n",
    "\n",
    "\n",
    "Train_Bin_List = []\n",
    "for i in range (0,len(Train_Array_Lengths)):\n",
    "    Train_Bin_List.append(Bin_Time(Train_Array_Lengths[i],Initial_Num_Bins)) # bin the time based on the sizes of each series. \n",
    "Train_Time_Bins = np.uint8(np.concatenate(Train_Bin_List, axis = 0))\n",
    "\n",
    "\n",
    "Test_Bin_List = []\n",
    "for i in range (0,len(Test_Array_Lengths)):\n",
    "    Test_Bin_List.append(Bin_Time(Test_Array_Lengths[i],Initial_Num_Bins)) # bin the time based on the sizes of each series. \n",
    "Test_Time_Bins = np.uint8(np.concatenate(Test_Bin_List, axis = 0))\n",
    "\n",
    "print \"Time Bin Creation Complete: \", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LogReg = LogisticRegression(C = C_Value, penalty = penalty,tol=Convergence_tol) \n",
    "rfe = RFE(LogReg,Reduced_Number_Of_Bin, step=Reduction_Step)\n",
    "\n",
    "\n",
    "#reduce Time_Bins to top x features for HandStart\n",
    "rfe.fit(Train_Time_Bins, Train_Labels_HandStart.to_dense())\n",
    "HandStart_Train_Features.append(rfe.transform(Train_Time_Bins)) # Add reduced set of features to full set\n",
    "HandStart_Test_Features.append(rfe.transform(Test_Time_Bins)) # Add reduced set of features to full set\n",
    "    \n",
    "#reduce Rolling_Means to top x features for FirstDigitTouch\n",
    "rfe.fit(Train_Time_Bins, Train_Labels_FirstDigitTouch.to_dense())\n",
    "FirstDigitTouch_Train_Features.append(rfe.transform(Train_Time_Bins)) # Add reduced set of features to full set\n",
    "FirstDigitTouch_Test_Features.append(rfe.transform(Test_Time_Bins)) # Add reduced set of features to full set\n",
    "    \n",
    "#reduce Rolling_Means to top x features for BothStartLoadPhase\n",
    "rfe.fit(Train_Time_Bins, Train_Labels_BothStartLoadPhase.to_dense())\n",
    "BothStartLoadPhase_Train_Features.append(rfe.transform(Train_Time_Bins)) # Add reduced set of features to full set\n",
    "BothStartLoadPhase_Test_Features.append(rfe.transform(Test_Time_Bins)) # Add reduced set of features to full set\n",
    "    \n",
    "#reduce Rolling_Means to top x features for LiftOff\n",
    "rfe.fit(Train_Time_Bins, Train_Labels_LiftOff.to_dense())\n",
    "LiftOff_Train_Features.append(rfe.transform(Train_Time_Bins)) # Add reduced set of features to full set\n",
    "LiftOff_Test_Features.append(rfe.transform(Test_Time_Bins)) # Add reduced set of features to full set\n",
    "    \n",
    "#reduce Rolling_Means to top x features for Replace\n",
    "rfe.fit(Train_Time_Bins, Train_Labels_Replace.to_dense())\n",
    "Replace_Train_Features.append(rfe.transform(Train_Time_Bins)) # Add reduced set of features to full set\n",
    "Replace_Test_Features.append(rfe.transform(Test_Time_Bins)) # Add reduced set of features to full set\n",
    "    \n",
    "#reduce Rolling_Means to top x features for BothReleased\n",
    "rfe.fit(Train_Time_Bins, Train_Labels_BothReleased.to_dense())\n",
    "BothReleased_Train_Features.append(rfe.transform(Train_Time_Bins)) # Add reduced set of features to full set\n",
    "BothReleased_Test_Features.append(rfe.transform(Test_Time_Bins)) # Add reduced set of features to full set    \n",
    "\n",
    "\n",
    "del Train_Time_Bins\n",
    "del Test_Time_Bins\n",
    "\n",
    "print \"Time Bins Added to Feature Sets For Each Event: \", int(time.time()-Start_Time), \" Seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling Mean With Window Size  10  Complete:  52  Seconds\n",
      "Rolling Variance With Window Size  10  Complete:  74  Seconds\n",
      "Rolling Skew With Window Size  10  Complete:  82  Seconds\n",
      "Rolling Kurtosis With Window Size  10  Complete:  89  Seconds\n",
      "Rolling Min With Window Size  10  Complete:  108  Seconds\n",
      "Rolling Max With Window Size  10  Complete:  142  Seconds\n",
      "Rolling Mean With Window Size  50  Complete:  201  Seconds\n",
      "Rolling Variance With Window Size  50  Complete:  225  Seconds\n",
      "Rolling Skew With Window Size  50  Complete:  235  Seconds\n",
      "Rolling Kurtosis With Window Size  50  Complete:  244  Seconds\n",
      "Rolling Min With Window Size  50  Complete:  261  Seconds\n",
      "Rolling Max With Window Size  50  Complete:  295  Seconds\n",
      "Rolling Mean With Window Size  100  Complete:  350  Seconds\n",
      "Rolling Variance With Window Size  100  Complete:  384  Seconds\n",
      "Rolling Skew With Window Size  100  Complete:  397  Seconds\n",
      "Rolling Kurtosis With Window Size  100  Complete:  406  Seconds\n",
      "Rolling Min With Window Size  100  Complete:  423  Seconds\n",
      "Rolling Max With Window Size  100  Complete:  450  Seconds\n"
     ]
    }
   ],
   "source": [
    "#     #reduce Rolling_Means to top x features for HandStart\n",
    "#     rfe.fit(RawData_Rolling_Means_Train, Train_Labels_HandStart.to_dense())\n",
    "#     HandStart_Train_Features.append(rfe.transform(RawData_Rolling_Means_Train)) # Add reduced set of features to full set\n",
    "#     HandStart_Test_Features.append(rfe.transform(RawData_Rolling_Means_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Means to top x features for FirstDigitTouch\n",
    "#     rfe.fit(RawData_Rolling_Means_Train, Train_Labels_FirstDigitTouch.to_dense())\n",
    "#     FirstDigitTouch_Train_Features.append(rfe.transform(RawData_Rolling_Means_Train)) # Add reduced set of features to full set\n",
    "#     FirstDigitTouch_Test_Features.append(rfe.transform(RawData_Rolling_Means_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Means to top x features for BothStartLoadPhase\n",
    "#     rfe.fit(RawData_Rolling_Means_Train, Train_Labels_BothStartLoadPhase.to_dense())\n",
    "#     BothStartLoadPhase_Train_Features.append(rfe.transform(RawData_Rolling_Means_Train)) # Add reduced set of features to full set\n",
    "#     BothStartLoadPhase_Test_Features.append(rfe.transform(RawData_Rolling_Means_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Means to top x features for LiftOff\n",
    "#     rfe.fit(RawData_Rolling_Means_Train, Train_Labels_LiftOff.to_dense())\n",
    "#     LiftOff_Train_Features.append(rfe.transform(RawData_Rolling_Means_Train)) # Add reduced set of features to full set\n",
    "#     LiftOff_Test_Features.append(rfe.transform(RawData_Rolling_Means_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Means to top x features for Replace\n",
    "#     rfe.fit(RawData_Rolling_Means_Train, Train_Labels_Replace.to_dense())\n",
    "#     Replace_Train_Features.append(rfe.transform(RawData_Rolling_Means_Train)) # Add reduced set of features to full set\n",
    "#     Replace_Test_Features.append(rfe.transform(RawData_Rolling_Means_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Means to top x features for BothReleased\n",
    "#     rfe.fit(RawData_Rolling_Means_Train, Train_Labels_BothReleased.to_dense())\n",
    "#     BothReleased_Train_Features.append(rfe.transform(RawData_Rolling_Means_Train)) # Add reduced set of features to full set\n",
    "#     BothReleased_Test_Features.append(rfe.transform(RawData_Rolling_Means_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     print \"Rolling Mean With Window Size \", w, \" Complete: \", int(time.time()-Start_Time), \" Seconds\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#     #reduce Rolling_Var to top x features for HandStart\n",
    "#     rfe.fit(RawData_Rolling_Var_Train, Train_Labels_HandStart.to_dense())\n",
    "#     HandStart_Train_Features.append(rfe.transform(RawData_Rolling_Var_Train)) # Add reduced set of features to full set\n",
    "#     HandStart_Test_Features.append(rfe.transform(RawData_Rolling_Var_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Var to top x features for FirstDigitTouch\n",
    "#     rfe.fit(RawData_Rolling_Var_Train, Train_Labels_FirstDigitTouch.to_dense())\n",
    "#     FirstDigitTouch_Train_Features.append(rfe.transform(RawData_Rolling_Var_Train)) # Add reduced set of features to full set\n",
    "#     FirstDigitTouch_Test_Features.append(rfe.transform(RawData_Rolling_Var_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Var to top x features for BothStartLoadPhase\n",
    "#     rfe.fit(RawData_Rolling_Means_Train, Train_Labels_BothStartLoadPhase.to_dense())\n",
    "#     BothStartLoadPhase_Train_Features.append(rfe.transform(RawData_Rolling_Var_Train)) # Add reduced set of features to full set\n",
    "#     BothStartLoadPhase_Test_Features.append(rfe.transform(RawData_Rolling_Var_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Var to top x features for LiftOff\n",
    "#     rfe.fit(RawData_Rolling_Means_Train, Train_Labels_LiftOff.to_dense())\n",
    "#     LiftOff_Train_Features.append(rfe.transform(RawData_Rolling_Var_Train)) # Add reduced set of features to full set\n",
    "#     LiftOff_Test_Features.append(rfe.transform(RawData_Rolling_Var_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Var to top x features for Replace\n",
    "#     rfe.fit(RawData_Rolling_Means_Train, Train_Labels_Replace.to_dense())\n",
    "#     Replace_Train_Features.append(rfe.transform(RawData_Rolling_Var_Train)) # Add reduced set of features to full set\n",
    "#     Replace_Test_Features.append(rfe.transform(RawData_Rolling_Var_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Var to top x features for BothReleased\n",
    "#     rfe.fit(RawData_Rolling_Means_Train, Train_Labels_BothReleased.to_dense())\n",
    "#     BothReleased_Train_Features.append(rfe.transform(RawData_Rolling_Var_Train)) # Add reduced set of features to full set\n",
    "#     BothReleased_Test_Features.append(rfe.transform(RawData_Rolling_Var_Test)) # Add reduced set of features to full set\n",
    "#     print \"Rolling Variance With Window Size \", w, \" Complete: \", int(time.time()-Start_Time), \" Seconds\"\n",
    "    \n",
    "    \n",
    "\n",
    "#     #reduce Rolling_Skewness to top x features for HandStart\n",
    "#     rfe.fit(RawData_Rolling_Skewness_Train, Train_Labels_HandStart.to_dense())\n",
    "#     HandStart_Train_Features.append(rfe.transform(RawData_Rolling_Skewness_Train)) # Add reduced set of features to full set\n",
    "#     HandStart_Test_Features.append(rfe.transform(RawData_Rolling_Skewness_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Skewness to top x features for FirstDigitTouch\n",
    "#     rfe.fit(RawData_Rolling_Skewness_Train, Train_Labels_FirstDigitTouch.to_dense())\n",
    "#     FirstDigitTouch_Train_Features.append(rfe.transform(RawData_Rolling_Skewness_Train)) # Add reduced set of features to full set\n",
    "#     FirstDigitTouch_Test_Features.append(rfe.transform(RawData_Rolling_Skewness_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Skewness to top x features for BothStartLoadPhase\n",
    "#     rfe.fit(RawData_Rolling_Skewness_Train, Train_Labels_BothStartLoadPhase.to_dense())\n",
    "#     BothStartLoadPhase_Train_Features.append(rfe.transform(RawData_Rolling_Skewness_Train)) # Add reduced set of features to full set\n",
    "#     BothStartLoadPhase_Test_Features.append(rfe.transform(RawData_Rolling_Skewness_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Skewness to top x features for LiftOff\n",
    "#     rfe.fit(RawData_Rolling_Skewness_Train, Train_Labels_LiftOff.to_dense())\n",
    "#     LiftOff_Train_Features.append(rfe.transform(RawData_Rolling_Skewness_Train)) # Add reduced set of features to full set\n",
    "#     LiftOff_Test_Features.append(rfe.transform(RawData_Rolling_Skewness_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Skewness to top x features for Replace\n",
    "#     rfe.fit(RawData_Rolling_Skewness_Train, Train_Labels_Replace.to_dense())\n",
    "#     Replace_Train_Features.append(rfe.transform(RawData_Rolling_Skewness_Train)) # Add reduced set of features to full set\n",
    "#     Replace_Test_Features.append(rfe.transform(RawData_Rolling_Skewness_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Skewness to top x features for BothReleased\n",
    "#     rfe.fit(RawData_Rolling_Skewness_Train, Train_Labels_BothReleased.to_dense())\n",
    "#     BothReleased_Train_Features.append(rfe.transform(RawData_Rolling_Skewness_Train)) # Add reduced set of features to full set\n",
    "#     BothReleased_Test_Features.append(rfe.transform(RawData_Rolling_Skewness_Test)) # Add reduced set of features to full set\n",
    "#     print \"Rolling Skew With Window Size \", w, \" Complete: \", int(time.time()-Start_Time), \" Seconds\"\n",
    "    \n",
    "    \n",
    "#     #reduce Rolling_Kurtosis to top x features for HandStart\n",
    "#     rfe.fit(RawData_Rolling_Kurtosis_Train, Train_Labels_HandStart.to_dense())\n",
    "#     HandStart_Train_Features.append(rfe.transform(RawData_Rolling_Kurtosis_Train)) # Add reduced set of features to full set\n",
    "#     HandStart_Test_Features.append(rfe.transform(RawData_Rolling_Kurtosis_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Kurtosis to top x features for FirstDigitTouch\n",
    "#     rfe.fit(RawData_Rolling_Kurtosis_Train, Train_Labels_FirstDigitTouch.to_dense())\n",
    "#     FirstDigitTouch_Train_Features.append(rfe.transform(RawData_Rolling_Kurtosis_Train)) # Add reduced set of features to full set\n",
    "#     FirstDigitTouch_Test_Features.append(rfe.transform(RawData_Rolling_Kurtosis_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Kurtosis to top x features for BothStartLoadPhase\n",
    "#     rfe.fit(RawData_Rolling_Kurtosis_Train, Train_Labels_BothStartLoadPhase.to_dense())\n",
    "#     BothStartLoadPhase_Train_Features.append(rfe.transform(RawData_Rolling_Kurtosis_Train)) # Add reduced set of features to full set\n",
    "#     BothStartLoadPhase_Test_Features.append(rfe.transform(RawData_Rolling_Kurtosis_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Kurtosis to top x features for LiftOff\n",
    "#     rfe.fit(RawData_Rolling_Kurtosis_Train, Train_Labels_LiftOff.to_dense())\n",
    "#     LiftOff_Train_Features.append(rfe.transform(RawData_Rolling_Kurtosis_Train)) # Add reduced set of features to full set\n",
    "#     LiftOff_Test_Features.append(rfe.transform(RawData_Rolling_Kurtosis_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Kurtosis to top x features for Replace\n",
    "#     rfe.fit(RawData_Rolling_Kurtosis_Train, Train_Labels_Replace.to_dense())\n",
    "#     Replace_Train_Features.append(rfe.transform(RawData_Rolling_Kurtosis_Train)) # Add reduced set of features to full set\n",
    "#     Replace_Test_Features.append(rfe.transform(RawData_Rolling_Kurtosis_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Kurtosis to top x features for BothReleased\n",
    "#     rfe.fit(RawData_Rolling_Kurtosis_Train, Train_Labels_BothReleased.to_dense())\n",
    "#     BothReleased_Train_Features.append(rfe.transform(RawData_Rolling_Kurtosis_Train)) # Add reduced set of features to full set\n",
    "#     BothReleased_Test_Features.append(rfe.transform(RawData_Rolling_Kurtosis_Test)) # Add reduced set of features to full set\n",
    "#     print \"Rolling Kurtosis With Window Size \", w, \" Complete: \", int(time.time()-Start_Time), \" Seconds\"\n",
    "    \n",
    "       \n",
    "        \n",
    "#     #reduce Rolling_Min to top x features for HandStart\n",
    "#     rfe.fit(RawData_Rolling_Min_Train, Train_Labels_HandStart.to_dense())\n",
    "#     HandStart_Train_Features.append(rfe.transform(RawData_Rolling_Min_Train)) # Add reduced set of features to full set\n",
    "#     HandStart_Test_Features.append(rfe.transform(RawData_Rolling_Min_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Min to top x features for FirstDigitTouch\n",
    "#     rfe.fit(RawData_Rolling_Min_Train, Train_Labels_FirstDigitTouch.to_dense())\n",
    "#     FirstDigitTouch_Train_Features.append(rfe.transform(RawData_Rolling_Min_Train)) # Add reduced set of features to full set\n",
    "#     FirstDigitTouch_Test_Features.append(rfe.transform(RawData_Rolling_Min_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Min to top x features for BothStartLoadPhase\n",
    "#     rfe.fit(RawData_Rolling_Min_Train, Train_Labels_BothStartLoadPhase.to_dense())\n",
    "#     BothStartLoadPhase_Train_Features.append(rfe.transform(RawData_Rolling_Min_Train)) # Add reduced set of features to full set\n",
    "#     BothStartLoadPhase_Test_Features.append(rfe.transform(RawData_Rolling_Min_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Min to top x features for LiftOff\n",
    "#     rfe.fit(RawData_Rolling_Min_Train, Train_Labels_LiftOff.to_dense())\n",
    "#     LiftOff_Train_Features.append(rfe.transform(RawData_Rolling_Min_Train)) # Add reduced set of features to full set\n",
    "#     LiftOff_Test_Features.append(rfe.transform(RawData_Rolling_Min_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Min to top x features for Replace\n",
    "#     rfe.fit(RawData_Rolling_Min_Train, Train_Labels_Replace.to_dense())\n",
    "#     Replace_Train_Features.append(rfe.transform(RawData_Rolling_Min_Train)) # Add reduced set of features to full set\n",
    "#     Replace_Test_Features.append(rfe.transform(RawData_Rolling_Min_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Min to top x features for BothReleased\n",
    "#     rfe.fit(RawData_Rolling_Min_Train, Train_Labels_BothReleased.to_dense())\n",
    "#     BothReleased_Train_Features.append(rfe.transform(RawData_Rolling_Min_Train)) # Add reduced set of features to full set\n",
    "#     BothReleased_Test_Features.append(rfe.transform(RawData_Rolling_Min_Test)) # Add reduced set of features to full set \n",
    "#     print \"Rolling Min With Window Size \", w, \" Complete: \", int(time.time()-Start_Time), \" Seconds\"\n",
    "    \n",
    "    \n",
    "#     #reduce Rolling_Max to top x features for HandStart\n",
    "#     rfe.fit(RawData_Rolling_Max_Train, Train_Labels_HandStart.to_dense())\n",
    "#     HandStart_Train_Features.append(rfe.transform(RawData_Rolling_Max_Train)) # Add reduced set of features to full set\n",
    "#     HandStart_Test_Features.append(rfe.transform(RawData_Rolling_Max_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Max to top x features for FirstDigitTouch\n",
    "#     rfe.fit(RawData_Rolling_Max_Train, Train_Labels_FirstDigitTouch.to_dense())\n",
    "#     FirstDigitTouch_Train_Features.append(rfe.transform(RawData_Rolling_Max_Train)) # Add reduced set of features to full set\n",
    "#     FirstDigitTouch_Test_Features.append(rfe.transform(RawData_Rolling_Max_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Max to top x features for BothStartLoadPhase\n",
    "#     rfe.fit(RawData_Rolling_Max_Train, Train_Labels_BothStartLoadPhase.to_dense())\n",
    "#     BothStartLoadPhase_Train_Features.append(rfe.transform(RawData_Rolling_Max_Train)) # Add reduced set of features to full set\n",
    "#     BothStartLoadPhase_Test_Features.append(rfe.transform(RawData_Rolling_Max_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Max to top x features for LiftOff\n",
    "#     rfe.fit(RawData_Rolling_Max_Train, Train_Labels_LiftOff.to_dense())\n",
    "#     LiftOff_Train_Features.append(rfe.transform(RawData_Rolling_Max_Train)) # Add reduced set of features to full set\n",
    "#     LiftOff_Test_Features.append(rfe.transform(RawData_Rolling_Max_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Max to top x features for Replace\n",
    "#     rfe.fit(RawData_Rolling_Max_Train, Train_Labels_Replace.to_dense())\n",
    "#     Replace_Train_Features.append(rfe.transform(RawData_Rolling_Max_Train)) # Add reduced set of features to full set\n",
    "#     Replace_Test_Features.append(rfe.transform(RawData_Rolling_Max_Test)) # Add reduced set of features to full set\n",
    "    \n",
    "#     #reduce Rolling_Max to top x features for BothReleased\n",
    "#     rfe.fit(RawData_Rolling_Max_Train, Train_Labels_BothReleased.to_dense())\n",
    "#     BothReleased_Train_Features.append(rfe.transform(RawData_Rolling_Max_Train)) # Add reduced set of features to full set\n",
    "#     BothReleased_Test_Features.append(rfe.transform(RawData_Rolling_Max_Test)) # Add reduced set of features to full set \n",
    "#     print \"Rolling Max With Window Size \", w, \" Complete: \", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# #Now do the same thing but for the binned time    \n",
    "\n",
    "\n",
    "# Num_Bins = 200\n",
    "\n",
    "\n",
    "# Train_Bin_List = []\n",
    "# for i in range (0,len(Train_Array_Lengths)):\n",
    "#     Train_Bin_List.append(Bin_Time(Train_Array_Lengths[i],Num_Bins)) # bin the time based on the sizes of each series. \n",
    "# Train_Time_Bins = np.concatenate(Train_Bin_List, axis = 0)\n",
    "\n",
    "\n",
    "# Test_Bin_List = []\n",
    "# for i in range (0,len(Test_Array_Lengths)):\n",
    "#     Test_Bin_List.append(Bin_Time(Test_Array_Lengths[i],Num_Bins)) # bin the time based on the sizes of each series. \n",
    "# Test_Time_Bins = np.concatenate(Test_Bin_List, axis = 0)\n",
    "\n",
    "# print \"Time Bin Creation Complete: \", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "# C_Value = 1\n",
    "# penalty = 'l1'\n",
    "# Convergence_tol = .1\n",
    "\n",
    "# LogReg = LogisticRegression(C = C_Value, penalty = penalty,tol=Convergence_tol) \n",
    "# rfe = RFE(LogReg,20, step=20)\n",
    "\n",
    "\n",
    "# #reduce Time_Bins to top x features for HandStart\n",
    "# rfe.fit(Train_Time_Bins, Train_Labels_HandStart.to_dense())\n",
    "# HandStart_Train_Features.append(rfe.transform(Train_Time_Bins)) # Add reduced set of features to full set\n",
    "# HandStart_Test_Features.append(rfe.transform(Test_Time_Bins)) # Add reduced set of features to full set\n",
    "    \n",
    "# #reduce Rolling_Means to top x features for FirstDigitTouch\n",
    "# rfe.fit(Train_Time_Bins, Train_Labels_FirstDigitTouch.to_dense())\n",
    "# FirstDigitTouch_Train_Features.append(rfe.transform(Train_Time_Bins)) # Add reduced set of features to full set\n",
    "# FirstDigitTouch_Test_Features.append(rfe.transform(Test_Time_Bins)) # Add reduced set of features to full set\n",
    "    \n",
    "# #reduce Rolling_Means to top x features for BothStartLoadPhase\n",
    "# rfe.fit(Train_Time_Bins, Train_Labels_BothStartLoadPhase.to_dense())\n",
    "# BothStartLoadPhase_Train_Features.append(rfe.transform(Train_Time_Bins)) # Add reduced set of features to full set\n",
    "# BothStartLoadPhase_Test_Features.append(rfe.transform(Test_Time_Bins)) # Add reduced set of features to full set\n",
    "    \n",
    "# #reduce Rolling_Means to top x features for LiftOff\n",
    "# rfe.fit(Train_Time_Bins, Train_Labels_LiftOff.to_dense())\n",
    "# LiftOff_Train_Features.append(rfe.transform(Train_Time_Bins)) # Add reduced set of features to full set\n",
    "# LiftOff_Test_Features.append(rfe.transform(Test_Time_Bins)) # Add reduced set of features to full set\n",
    "    \n",
    "# #reduce Rolling_Means to top x features for Replace\n",
    "# rfe.fit(Train_Time_Bins, Train_Labels_Replace.to_dense())\n",
    "# Replace_Train_Features.append(rfe.transform(Train_Time_Bins)) # Add reduced set of features to full set\n",
    "# Replace_Test_Features.append(rfe.transform(Test_Time_Bins)) # Add reduced set of features to full set\n",
    "    \n",
    "# #reduce Rolling_Means to top x features for BothReleased\n",
    "# rfe.fit(Train_Time_Bins, Train_Labels_BothReleased.to_dense())\n",
    "# BothReleased_Train_Features.append(rfe.transform(Train_Time_Bins)) # Add reduced set of features to full set\n",
    "# BothReleased_Test_Features.append(rfe.transform(Test_Time_Bins)) # Add reduced set of features to full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HandStart_Test_Features = np.float32(np.concatenate((HandStart_Test_Features),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "FirstDigitTouch_Test_Features = np.float32(np.concatenate((FirstDigitTouch_Test_Features),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "BothStartLoadPhase_Test_Features = np.float32(np.concatenate((BothStartLoadPhase_Test_Features),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "LiftOff_Test_Features = np.float32(np.concatenate((LiftOff_Test_Features),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "Replace_Test_Features = np.float32(np.concatenate((Replace_Test_Features),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "BothReleased_Test_Features = np.float32(np.concatenate((BothReleased_Test_Features),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "HandStart_Train_Features =np.float32( np.concatenate((HandStart_Train_Features),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "FirstDigitTouch_Train_Features = np.float32(np.concatenate((FirstDigitTouch_Train_Features),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "BothStartLoadPhase_Train_Features = np.float32(np.concatenate((BothStartLoadPhase_Train_Features),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "LiftOff_Train_Features = np.float32(np.concatenate((LiftOff_Train_Features),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "Replace_Train_Features = np.float32(np.concatenate((Replace_Train_Features),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "BothReleased_Train_Features = np.float32(np.concatenate((BothReleased_Train_Features),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "HandStart_Test_Features = np.float32(np.concatenate((HandStart_Test_Features,Test_Data),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "FirstDigitTouch_Test_Features = np.float32(np.concatenate((FirstDigitTouch_Test_Features,Test_Data),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "BothStartLoadPhase_Test_Features = np.float32(np.concatenate((BothStartLoadPhase_Test_Features,Test_Data),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "LiftOff_Test_Features = np.float32(np.concatenate((LiftOff_Test_Features,Test_Data),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "Replace_Test_Features = np.float32(np.concatenate((Replace_Test_Features,Test_Data),axis = 1))\n",
    "gc.collect()\n",
    "\n",
    "BothReleased_Test_Features = np.float32(np.concatenate((BothReleased_Test_Features,Test_Data),axis = 1))\n",
    "gc.collect()\n",
    "del Test_Data\n",
    "\n",
    "HandStart_Train_Features =np.float32( np.concatenate((HandStart_Train_Features,Train_Data),axis = 1))\n",
    "FirstDigitTouch_Train_Features = np.float32(np.concatenate((FirstDigitTouch_Train_Features,Train_Data),axis = 1))\n",
    "BothStartLoadPhase_Train_Features = np.float32(np.concatenate((BothStartLoadPhase_Train_Features,Train_Data),axis = 1))\n",
    "LiftOff_Train_Features = np.float32(np.concatenate((LiftOff_Train_Features,Train_Data),axis = 1))\n",
    "Replace_Train_Features = np.float32(np.concatenate((Replace_Train_Features,Train_Data),axis = 1))\n",
    "BothReleased_Train_Features = np.float32(np.concatenate((BothReleased_Train_Features,Train_Data),axis = 1))\n",
    "\n",
    "\n",
    "del Train_Data\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HandStart_Train_Features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-93efb3de5413>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mHandStart_Train_Features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mHandStart_Test_Features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mFirstDigitTouch_Train_Features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mFirstDigitTouch_Test_Features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'HandStart_Train_Features' is not defined"
     ]
    }
   ],
   "source": [
    "print HandStart_Train_Features.shape\n",
    "print HandStart_Test_Features.shape\n",
    "\n",
    "print FirstDigitTouch_Train_Features.shape\n",
    "print FirstDigitTouch_Test_Features.shape\n",
    "\n",
    "print BothStartLoadPhase_Train_Features.shape\n",
    "print BothStartLoadPhase_Test_Features.shape\n",
    "\n",
    "print LiftOff_Train_Features.shape\n",
    "print LiftOff_Test_Features.shape\n",
    "\n",
    "print Replace_Train_Features.shape\n",
    "print Replace_Test_Features.shape\n",
    "\n",
    "print BothReleased_Train_Features.shape\n",
    "print BothReleased_Test_Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "934.12653"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 934.12651\n",
    "\n",
    "np.float32(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintain x% of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on the number of features remaining from the previous section, we can further reduce the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#since the recursive feature elimination uses the coefficients as a means to eliminate features, \n",
    "# we must first scale the data. \n",
    "Scale_Center = StandardScaler()\n",
    "Z_HandStart_Train_Features = np.float16(Scale_Center.fit_transform(np.array(HandStart_Train_Features)))\n",
    "del HandStart_Train_Features \n",
    "gc.collect()\n",
    "\n",
    "\n",
    "Z_HandStart_Test_Features = np.float16(Scale_Center.fit_transform(np.array(HandStart_Test_Features)))\n",
    "del HandStart_Test_Features \n",
    "gc.collect()\n",
    "\n",
    "\n",
    "Z_FirstDigitTouch_Train_Features = np.float16(Scale_Center.fit_transform(np.array(FirstDigitTouch_Train_Features)))\n",
    "del FirstDigitTouch_Train_Features \n",
    "gc.collect()\n",
    "\n",
    "Z_FirstDigitTouch_Test_Features = np.float16(Scale_Center.fit_transform(np.array(FirstDigitTouch_Test_Features)))\n",
    "del FirstDigitTouch_Test_Features \n",
    "gc.collect()\n",
    "\n",
    "Z_BothStartLoadPhase_Train_Features = np.float16(Scale_Center.fit_transform(np.array(BothStartLoadPhase_Train_Features)))\n",
    "del BothStartLoadPhase_Train_Features \n",
    "gc.collect()\n",
    "\n",
    "Z_BothStartLoadPhase_Test_Features = np.float16(Scale_Center.fit_transform(np.array(BothStartLoadPhase_Test_Features)))\n",
    "del BothStartLoadPhase_Test_Features \n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "Z_LiftOff_Train_Features = np.float16(Scale_Center.fit_transform(np.array(LiftOff_Train_Features)))\n",
    "del LiftOff_Train_Features \n",
    "gc.collect()\n",
    "\n",
    "Z_LiftOff_Test_Features = np.float16(Scale_Center.fit_transform(np.array(LiftOff_Test_Features)))\n",
    "del LiftOff_Test_Features \n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "Z_Replace_Train_Features = np.float16(Scale_Center.fit_transform(np.array(Replace_Train_Features)))\n",
    "del Replace_Train_Features \n",
    "gc.collect()\n",
    "\n",
    "Z_Replace_Test_Features = np.float16(Scale_Center.fit_transform(np.array(Replace_Test_Features)))\n",
    "del Replace_Test_Features \n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "Z_BothReleased_Train_Features = np.float16(Scale_Center.fit_transform(np.array(BothReleased_Train_Features)))\n",
    "del BothReleased_Train_Features \n",
    "gc.collect()\n",
    "\n",
    "Z_BothReleased_Test_Features = np.float16(Scale_Center.fit_transform(np.array(BothReleased_Test_Features)))\n",
    "del BothReleased_Test_Features \n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391450L, 58L)\n"
     ]
    }
   ],
   "source": [
    "print HandStart_PCs_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HandStart_PCs Complete: 15  Seconds\n",
      "FirstDigitTouch_PCs Complete: 30  Seconds\n",
      "BothStartLoadPhase_PCs Complete: 44  Seconds\n",
      "LiftOff_PCs Complete: 60  Seconds\n",
      "Replace_PCs Complete: 75  Seconds\n",
      "BothReleased_PCs Complete: 89  Seconds\n"
     ]
    }
   ],
   "source": [
    "Pct_Variance_Explained = .9\n",
    "Start_Time = time.time()\n",
    "\n",
    "HandStart_PCs_Train,HandStart_PCs_Test = extractFeatures_PCA(Z_HandStart_Train_Features,Z_HandStart_Test_Features,Pct_Variance_Explained)\n",
    "del Z_HandStart_Train_Features,Z_HandStart_Test_Features \n",
    "gc.collect()\n",
    "print \"HandStart_PCs Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "FirstDigitTouch_PCs_Train, FirstDigitTouch_PCs_Test = extractFeatures_PCA(Z_FirstDigitTouch_Train_Features,Z_FirstDigitTouch_Test_Features,Pct_Variance_Explained)\n",
    "del Z_FirstDigitTouch_Train_Features,Z_FirstDigitTouch_Test_Features\n",
    "gc.collect()\n",
    "print \"FirstDigitTouch_PCs Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "BothStartLoadPhase_PCs_Train, BothStartLoadPhase_PCs_Test =extractFeatures_PCA(Z_BothStartLoadPhase_Train_Features,Z_BothStartLoadPhase_Test_Features,Pct_Variance_Explained)\n",
    "del Z_BothStartLoadPhase_Train_Features,Z_BothStartLoadPhase_Test_Features\n",
    "gc.collect()\n",
    "print \"BothStartLoadPhase_PCs Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "LiftOff_PCs_Train, LiftOff_PCs_Test = extractFeatures_PCA(Z_LiftOff_Train_Features,Z_LiftOff_Test_Features,Pct_Variance_Explained)\n",
    "del Z_LiftOff_Train_Features,Z_LiftOff_Test_Features\n",
    "gc.collect()\n",
    "print \"LiftOff_PCs Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "Replace_PCs_Train, Replace_PCs_Test = extractFeatures_PCA(Z_Replace_Train_Features,Z_Replace_Test_Features,Pct_Variance_Explained)\n",
    "del Z_Replace_Train_Features,Z_Replace_Test_Features\n",
    "gc.collect()\n",
    "print \"Replace_PCs Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "\n",
    "BothReleased_PCs_Train, BothReleased_PCs_Test = extractFeatures_PCA(Z_BothReleased_Train_Features,Z_BothReleased_Test_Features,Pct_Variance_Explained)\n",
    "del Z_BothReleased_Train_Features,Z_BothReleased_Test_Features\n",
    "gc.collect()\n",
    "print \"BothReleased_PCs Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Percent_Features_To_Keep = .7\n",
    "Num_Steps = 2\n",
    "Num_Features = Z_BothReleased_Test_Features.shape[1]\n",
    "\n",
    "C_Value = 1\n",
    "penalty = 'l1'\n",
    "Convergence_tol = .01\n",
    "\n",
    "Num_Features_To_Keep = int(Num_Features*Percent_Features_To_Keep)\n",
    "RFE_Step = int((Num_Features-Num_Features_To_Keep)/Num_Steps)\n",
    "\n",
    "Start_Time = time.time()\n",
    "\n",
    "LogReg = LogisticRegression(C = C_Value, penalty = penalty,tol=Convergence_tol) \n",
    "rfe = RFE(LogReg,Num_Features_To_Keep, step=RFE_Step)\n",
    "\n",
    "#reduce entire feature set to top x features for HandStart\n",
    "rfe.fit(Z_HandStart_Train_Features, Train_Labels_HandStart.to_dense())\n",
    "HandStart_Train_Reduced_Features = np.float16(rfe.transform(Z_HandStart_Train_Features))\n",
    "del Z_HandStart_Train_Features\n",
    "gc.collect()\n",
    "print \"HandStart_Train_Reduced_Features Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "HandStart_Test_Reduced_Features = np.float16(rfe.transform(Z_HandStart_Test_Features))\n",
    "del Z_HandStart_Test_Features\n",
    "gc.collect()\n",
    "print \"HandStart_Test_Reduced_Features Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "    \n",
    "#reduce entire feature set  to top x features for FirstDigitTouch\n",
    "rfe.fit(Z_FirstDigitTouch_Train_Features, Train_Labels_FirstDigitTouch.to_dense())\n",
    "FirstDigitTouch_Train_Reduced_Features = np.float16(rfe.transform(Z_FirstDigitTouch_Train_Features))\n",
    "del Z_FirstDigitTouch_Train_Features\n",
    "gc.collect()\n",
    "print \"FirstDigitTouch_Train_Reduced_Features Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "FirstDigitTouch_TestReduced__Features = np.float16(rfe.transform(Z_FirstDigitTouch_Test_Features))\n",
    "del Z_FirstDigitTouch_Test_Features\n",
    "gc.collect()\n",
    "print \"FirstDigitTouch_TestReduced__Features Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "    \n",
    "#reduce entire feature set  to top x features for BothStartLoadPhase\n",
    "rfe.fit(Z_BothStartLoadPhase_Train_Features, Train_Labels_BothStartLoadPhase.to_dense())\n",
    "BothStartLoadPhase_Train_Reduced_Features = np.float16(rfe.transform(Z_BothStartLoadPhase_Train_Features))\n",
    "del Z_BothStartLoadPhase_Train_Features\n",
    "gc.collect()\n",
    "print \"BothStartLoadPhase_Train_Reduced_Features Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "BothStartLoadPhase_Test_Reduced_Features = np.float16(rfe.transform(Z_BothStartLoadPhase_Test_Features)) \n",
    "del Z_BothStartLoadPhase_Test_Features\n",
    "gc.collect()\n",
    "print \"BothStartLoadPhase_Test_Reduced_Features Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "\n",
    "#reduce entire feature set  to top x features for LiftOff\n",
    "rfe.fit(Z_LiftOff_Train_Features, Train_Labels_LiftOff.to_dense())\n",
    "LiftOff_Train_Reduced_Features = np.float16(rfe.transform(Z_LiftOff_Train_Features))\n",
    "del Z_LiftOff_Train_Features\n",
    "gc.collect()\n",
    "print \"LiftOff_Train_Reduced_Features Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "LiftOff_Test_Reduced_Features = np.float16(rfe.transform(Z_LiftOff_Test_Features)) \n",
    "del Z_LiftOff_Test_Features\n",
    "gc.collect()\n",
    "print \"LiftOff_Test_Reduced_Features Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "    \n",
    "#reduce entire feature set  to top x features for Replace\n",
    "rfe.fit(Z_Replace_Train_Features, Train_Labels_Replace.to_dense())\n",
    "Replace_Train_Reduced_Features = np.float16(rfe.transform(Z_Replace_Train_Features) )\n",
    "del Z_Replace_Train_Features\n",
    "gc.collect()\n",
    "print \"Replace_Train_Reduced_Features Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "Replace_Test_Reduced_Features = np.float16(rfe.transform(Z_Replace_Test_Features))\n",
    "del Z_Replace_Test_Features\n",
    "gc.collect()\n",
    "print \"Replace_Test_Reduced_Features Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "    \n",
    "#reduce entire feature set  to top x features for BothReleased\n",
    "rfe.fit(Z_BothReleased_Train_Features, Train_Labels_BothReleased.to_dense())\n",
    "BothReleased_Train_Reduced_Features = np.float16(rfe.transform(Z_BothReleased_Train_Features))\n",
    "del Z_BothReleased_Train_Features\n",
    "gc.collect()\n",
    "print \"BothReleased_Train_Reduced_Features Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "\n",
    "BothReleased_Test_Reduced_Features = np.float16(rfe.transform(Z_BothReleased_Test_Features))\n",
    "del Z_BothReleased_Test_Features\n",
    "gc.collect()\n",
    "print \"BothReleased_Test_Reduced_Features Complete:\", int(time.time()-Start_Time), \" Seconds\"\n",
    "   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Different Models\n",
    "\n",
    "##Logistic Regession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('HandStart', ' Score =', 0.98024024189620151)\n",
      "('HandStart', 'AUC', 0.72901344112293254)\n",
      "('FirstDigitTouch', ' Score =', 0.98007021607065725)\n",
      "('FirstDigitTouch', 'AUC', 0.71988603193346079)\n",
      "('BothStartLoadPhase', ' Score =', 0.98023105131103694)\n",
      "('BothStartLoadPhase', 'AUC', 0.72491754512914097)\n",
      "('LiftOff', ' Score =', 0.98045622064756865)\n",
      "('LiftOff', 'AUC', 0.73913876482865626)\n",
      "('Replace', ' Score =', 0.97736818403227732)\n",
      "('Replace', 'AUC', 0.67686674000946967)\n",
      "('BothReleased', ' Score =', 0.97745549459134062)\n",
      "('BothReleased', 'AUC', 0.6705658987427523)\n",
      "109  Seconds to complete\n",
      "Overall Logistic Regression Score =  0.710064736961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#set parameters for Logistic Regression\n",
    "#Setting them here will allow the optimization of the parameters. We saw in project 2 how much the C-value can affect the results. \n",
    "C_Value = 1\n",
    "penalty = 'l1'\n",
    "Convergence_tol = .01\n",
    "\n",
    "#Create a function that trains and runs a logistic regression model. Then prints and returns the AUC score\n",
    "def predictCategory_LogReg(train_data, train_label, test_data, test_label, Category, C_Value,penalty, Convergence_tol):\n",
    "    Logistic_Reg = LogisticRegression(C = C_Value, penalty = penalty,tol=Convergence_tol)    \n",
    "    Logistic_Reg.fit(train_data, train_label)\n",
    "    print(Category, \" Score =\", Logistic_Reg.score(test_data, test_label))\n",
    "\n",
    "    prob = Logistic_Reg.predict_proba(test_data)\n",
    "    print(Category, \"AUC\", roc_auc_score(test_label, prob[:,1]))\n",
    "\n",
    "    #FPR, TPR, thresholds = roc_curve(Test_Labels_HandStart, prob[:,1])\n",
    "    return roc_auc_score(test_label, prob[:,1])\n",
    "\n",
    "Start_Time = time.time()   \n",
    "AUC_HandStart = predictCategory_LogReg(HandStart_PCs_Train,Train_Labels_HandStart.to_dense(),HandStart_PCs_Test,Test_Labels_HandStart.to_dense(), 'HandStart', C_Value,penalty, Convergence_tol)\n",
    "AUC_FirstDigitTouch = predictCategory_LogReg(FirstDigitTouch_PCs_Train,Train_Labels_FirstDigitTouch.to_dense(),FirstDigitTouch_PCs_Test,Test_Labels_FirstDigitTouch.to_dense(), 'FirstDigitTouch', C_Value,penalty, Convergence_tol)\n",
    "AUC_BothStartLoadPhase = predictCategory_LogReg(BothStartLoadPhase_PCs_Train,Train_Labels_BothStartLoadPhase.to_dense(),BothStartLoadPhase_PCs_Test,Test_Labels_BothStartLoadPhase.to_dense(), 'BothStartLoadPhase', C_Value,penalty, Convergence_tol)\n",
    "AUC_LiftOff = predictCategory_LogReg(LiftOff_PCs_Train,Train_Labels_LiftOff.to_dense(),LiftOff_PCs_Test,Test_Labels_LiftOff.to_dense(), 'LiftOff', C_Value,penalty, Convergence_tol)\n",
    "AUC_Replace = predictCategory_LogReg(Replace_PCs_Train,Train_Labels_Replace.to_dense(),Replace_PCs_Test,Test_Labels_Replace.to_dense(), 'Replace', C_Value,penalty, Convergence_tol)\n",
    "AUC_BothReleased = predictCategory_LogReg(BothReleased_PCs_Train,Train_Labels_BothReleased.to_dense(),BothReleased_PCs_Test,Test_Labels_BothReleased.to_dense(), 'BothReleased', C_Value,penalty, Convergence_tol)\n",
    "print int(time.time()-Start_Time), \" Seconds to complete\"\n",
    "print \"Overall Logistic Regression Score = \", np.mean((AUC_HandStart, AUC_FirstDigitTouch,AUC_BothStartLoadPhase,AUC_LiftOff,AUC_Replace,AUC_BothReleased))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a failed attempt at parallel processing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from multiprocessing import Process\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#set parameters for Logistic Regression\n",
    "#Setting them here will allow the optimization of the parameters. We saw in project 2 how much the C-value can affect the results. \n",
    "C_Value = 1\n",
    "penalty = 'l1'\n",
    "Convergence_tol = .01\n",
    "\n",
    "#Create a function that trains and runs a logistic regression model. Then prints and returns the AUC score\n",
    "def predictCategory_LogReg(train_data, train_label, test_data, test_label, Category, C_Value,penalty, Convergence_tol):\n",
    "    Logistic_Reg = LogisticRegression(C = C_Value, penalty = penalty,tol=Convergence_tol)    \n",
    "    Logistic_Reg.fit(train_data, train_label)\n",
    "    print(Category, \" Score =\", Logistic_Reg.score(test_data, test_label))\n",
    "\n",
    "    prob = Logistic_Reg.predict_proba(test_data)\n",
    "    print(Category, \"AUC\", roc_auc_score(test_label, prob[:,1]))\n",
    "\n",
    "    #FPR, TPR, thresholds = roc_curve(Test_Labels_HandStart, prob[:,1])\n",
    "    return roc_auc_score(test_label, prob[:,1])\n",
    "\n",
    "Start_Time = time.time()\n",
    "def Log_Reg_HandStart():\n",
    "    predictCategory_LogReg(Feature_Array_Train,Train_Labels_HandStart,Feature_Array_Test,Test_Labels_HandStart, 'HandStart', C_Value,penalty, Convergence_tol)\n",
    "\n",
    "    \n",
    "def Log_Reg_FirstDigitTouch():    \n",
    "    predictCategory_LogReg(Feature_Array_Train,Train_Labels_FirstDigitTouch,Feature_Array_Test,Test_Labels_FirstDigitTouch, 'FirstDigitTouch', C_Value,penalty, Convergence_tol)\n",
    "\n",
    "    \n",
    "def Log_Reg_BothStartLoadPhase():       \n",
    "    predictCategory_LogReg(Feature_Array_Train,Train_Labels_BothStartLoadPhase,Feature_Array_Test,Test_Labels_BothStartLoadPhase, 'BothStartLoadPhase', C_Value,penalty, Convergence_tol)\n",
    "\n",
    "    \n",
    "def Log_Reg_LiftOff():       \n",
    "    predictCategory_LogReg(Feature_Array_Train,Train_Labels_LiftOff,Feature_Array_Test,Test_Labels_LiftOff, 'LiftOff', C_Value,penalty, Convergence_tol)\n",
    "\n",
    "    \n",
    "def Log_Reg_Replace():     \n",
    "    predictCategory_LogReg(Feature_Array_Train,Train_Labels_Replace,Feature_Array_Test,Test_Labels_Replace, 'Replace', C_Value,penalty, Convergence_tol)\n",
    "\n",
    "    \n",
    "def Log_Reg_BothReleased():    \n",
    "    predictCategory_LogReg(Feature_Array_Train,Train_Labels_BothReleased,Feature_Array_Test,Test_Labels_BothReleased, 'BothReleased', C_Value,penalty, Convergence_tol)\n",
    "\n",
    "    \n",
    "\n",
    "def Overall_AUC(i):\n",
    "    if i == 1:\n",
    "        Log_Reg_HandStart()\n",
    "    if i == 2:\n",
    "        Log_Reg_FirstDigitTouch()\n",
    "    if i == 3:\n",
    "        Log_Reg_BothStartLoadPhase()\n",
    "    if i == 4:\n",
    "        Log_Reg_LiftOff()\n",
    "    if i == 5:\n",
    "        Log_Reg_Replace()\n",
    "    if i == 6:\n",
    "        Log_Reg_BothReleased()\n",
    "    \n",
    "# print Overall_AUC(AUC_Values)\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "pool = mp.Pool(processes=1)\n",
    "results = [pool.apply_async(Overall_AUC, args=(i,)) for i in range(1,7)]\n",
    "output = [p.get() for p in results]\n",
    "print(output)\n",
    "\n",
    "\n",
    "\n",
    "print time.time()-Start_Time\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is set up to get started. It has not been tested. MM 08/04/2015 11:30 A.M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set parameters for SVM\n",
    "#Setting them here will allow the optimization of the parameters. We saw in project 2 how much the C-value can affect the results. \n",
    "C_Value = 1\n",
    "kernel = 'rbf'\n",
    "degree = 3\n",
    "\n",
    "#Create a function that trains and runs a model. Then prints and returns the AUC score\n",
    "def predictCategory_SVM(train_data, train_label, test_data, test_label, Category, C_Value,kernel, degree):\n",
    "    SVM = SVC(C = C_Value, kernel = kernel,degree=degree)    \n",
    "    SVC.fit(train_data, train_label)\n",
    "\n",
    "    prob = SVC.predict_proba(test_data)\n",
    "    print(Category, \"AUC\", roc_auc_score(test_label, prob[:,1]))\n",
    "\n",
    "    #FPR, TPR, thresholds = roc_curve(Test_Labels_HandStart, prob[:,1])\n",
    "    return roc_auc_score(test_label, prob[:,1])\n",
    "    \n",
    "AUC_HandStart = predictCategory_SVM(Feature_Array_Train,Train_Labels_HandStart,Feature_Array_Test,Test_Labels_HandStart, 'HandStart', Category, C_Value,kernel, degree)\n",
    "AUC_FirstDigitTouch = predictCategory_SVM(Feature_Array_Train,Train_Labels_FirstDigitTouch,Feature_Array_Test,Test_Labels_FirstDigitTouch, 'FirstDigitTouch', Category, C_Value,kernel, degree)\n",
    "AUC_BothStartLoadPhase = predictCategory_SVM(Feature_Array_Train,Train_Labels_BothStartLoadPhase,Feature_Array_Test,Test_Labels_BothStartLoadPhase, 'BothStartLoadPhase', Category, C_Value,kernel, degree)\n",
    "AUC_LiftOff = predictCategory_SVM(Feature_Array_Train,Train_Labels_LiftOff,Feature_Array_Test,Test_Labels_LiftOff, 'LiftOff', Category, C_Value,kernel, degree)\n",
    "AUC_Replace = predictCategory_SVM(Feature_Array_Train,Train_Labels_Replace,Feature_Array_Test,Test_Labels_Replace, 'Replace', Category, C_Value,kernel, degree)\n",
    "AUC_BothReleased = predictCategory_SVM(Feature_Array_Train,Train_Labels_BothReleased,Feature_Array_Test,Test_Labels_BothReleased, 'BothReleased', Category, C_Value,kernel, degree\n",
    "\n",
    "\n",
    "print \"Overall SVM Score = \", np.mean(AUC_HandStart, AUC_FirstDigitTouch,AUC_BothStartLoadPhase,AUC_LiftOff,AUC_Replace,AUC_BothReleased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set parameters for Neural Network model\n",
    "#Setting them here will allow the optimization of the parameters. We saw in project 2 how much the C-value can affect the results. \n",
    "n_components = 10\n",
    "learning_rate = .1\n",
    "batch_size = 20000\n",
    "n_iter =1\n",
    "\n",
    "\n",
    "#Create a function that trains and runs a model. Then prints and returns the AUC score\n",
    "def predictCategory_Neural_Network(train_data, train_label, test_data, test_label, Category, C_Value,kernel, degree):\n",
    "    SVM = SVC(C = C_Value, kernel = kernel,degree=degree)    \n",
    "    SVC.fit(train_data, train_label)\n",
    "\n",
    "    prob = SVC.predict_proba(test_data)\n",
    "    print(Category, \"AUC\", roc_auc_score(test_label, prob[:,1]))\n",
    "\n",
    "    #FPR, TPR, thresholds = roc_curve(Test_Labels_HandStart, prob[:,1])\n",
    "    return roc_auc_score(test_label, prob[:,1])\n",
    "    \n",
    "AUC_HandStart = predictCategory_Neural_Network(Feature_Array_Train,Train_Labels_HandStart,Feature_Array_Test,Test_Labels_HandStart, 'HandStart', Category, C_Value,kernel, degree)\n",
    "AUC_FirstDigitTouch = predictCategory_Neural_Network(Feature_Array_Train,Train_Labels_FirstDigitTouch,Feature_Array_Test,Test_Labels_FirstDigitTouch, 'FirstDigitTouch', Category, C_Value,kernel, degree)\n",
    "AUC_BothStartLoadPhase = predictCategory_Neural_Network(Feature_Array_Train,Train_Labels_BothStartLoadPhase,Feature_Array_Test,Test_Labels_BothStartLoadPhase, 'BothStartLoadPhase', Category, C_Value,kernel, degree)\n",
    "AUC_LiftOff = predictCategory_Neural_Network(Feature_Array_Train,Train_Labels_LiftOff,Feature_Array_Test,Test_Labels_LiftOff, 'LiftOff', Category, C_Value,kernel, degree)\n",
    "AUC_Replace = predictCategory_Neural_Network(Feature_Array_Train,Train_Labels_Replace,Feature_Array_Test,Test_Labels_Replace, 'Replace', Category, C_Value,kernel, degree)\n",
    "AUC_BothReleased = predictCategory_Neural_Network(Feature_Array_Train,Train_Labels_BothReleased,Feature_Array_Test,Test_Labels_BothReleased, 'BothReleased', Category, C_Value,kernel, degree\n",
    "\n",
    "\n",
    "print \"Overall Neural Network Score = \", np.mean(AUC_HandStart, AUC_FirstDigitTouch,AUC_BothStartLoadPhase,AUC_LiftOff,AUC_Replace,AUC_BothReleased)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
