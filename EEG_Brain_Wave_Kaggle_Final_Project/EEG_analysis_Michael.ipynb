{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "\n",
    "from pandas import *\n",
    "\n",
    "# SK-learn libraries.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "\n",
    "# scipy\n",
    "from scipy.signal import butter, lfilter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the test data into a single csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1438711235.99 Merging...\n",
      "1438711235.99 C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train\\subj1_series1_data.csv\n",
      "1438711237.17 C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train\\subj1_series2_data.csv\n",
      "Merge Complete: 2.69600009918 total seconds\n",
      "1438711238.69 Merging...\n",
      "1438711238.69 C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train\\subj1_series1_events.csv\n",
      "1438711238.85 C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train\\subj1_series2_events.csv\n",
      "Merge Complete: 0.512000083923 total seconds\n",
      "1438711239.21 Merging...\n",
      "1438711239.21 C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train\\subj1_series3_data.csv\n",
      "Merge Complete: 1.16199994087 total seconds\n",
      "1438711240.38 Merging...\n",
      "1438711240.38 C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train\\subj1_series3_events.csv\n",
      "Merge Complete: 0.266999959946 total seconds\n"
     ]
    }
   ],
   "source": [
    "#Remove the channels we don't want \n",
    "def Remove_Channels(df):\n",
    "    df.drop(df.columns[[15,16,20,21,22,25,26,27,28,29,30,31,32]], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "path =r'C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train'\n",
    "train_data_filenames = glob.glob(path + \"/subj1_series[1-2]*data.csv\") #load only subject 1, series 1-3\n",
    "list_ = []\n",
    "Train_Array_Lengths = []\n",
    "Start_Time = time.time()\n",
    "print time.time(), \"Merging...\"\n",
    "\n",
    "for file_ in train_data_filenames:\n",
    "    print time.time(), file_\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(Remove_Channels(df))\n",
    "    Train_Array_Lengths.append(len(df))\n",
    "train_data = pd.concat(list_)\n",
    "\n",
    "print \"Merge Complete:\", time.time()-Start_Time, \"total seconds\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#now with event data\n",
    "path =r'C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train'\n",
    "train_event_filenames = glob.glob(path + \"/subj1_series[1-2]*events.csv\") #load only subject 1, series 1-3\n",
    "list_ = []\n",
    "\n",
    "Start_Time = time.time()\n",
    "print time.time(), \"Merging...\"\n",
    "\n",
    "for file_ in train_event_filenames:\n",
    "    print time.time(), file_\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "train_events = pd.concat(list_)\n",
    "\n",
    "print \"Merge Complete:\", time.time()-Start_Time, \"total seconds\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#do the same thing and now get your testing data\n",
    "test_data_filenames = glob.glob(path + \"/subj1_series3*data.csv\") #load only subject 1, series 1-3\n",
    "list_ = []\n",
    "Test_Array_Lengths = []\n",
    "Start_Time = time.time()\n",
    "print time.time(), \"Merging...\"\n",
    "\n",
    "for file_ in test_data_filenames:\n",
    "    print time.time(), file_\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(Remove_Channels(df))\n",
    "    Test_Array_Lengths.append(len(df))\n",
    "test_data = pd.concat(list_)\n",
    "\n",
    "print \"Merge Complete:\", time.time()-Start_Time, \"total seconds\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#now with event data\n",
    "path =r'C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train'\n",
    "test_event_filenames = glob.glob(path + \"/subj1_series3*events.csv\") #load only subject 1, series 1-3\n",
    "list_ = []\n",
    "\n",
    "Start_Time = time.time()\n",
    "print time.time(), \"Merging...\"\n",
    "\n",
    "for file_ in test_event_filenames:\n",
    "    print time.time(), file_\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "test_events = pd.concat(list_)\n",
    "\n",
    "print \"Merge Complete:\", time.time()-Start_Time, \"total seconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a simple model and make predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                id  Fp1  Fp2   F7   F3  Fz   F4   F8  FC5  FC1  FC2  FC6   T7  \\\n",
      "0  subj1_series3_0   16  274  243  240 -80  410 -731  466  310   93  319  385   \n",
      "1  subj1_series3_1   26  255  266  203 -93  408 -770  487  296   57  312  735   \n",
      "2  subj1_series3_2   65  206  300  221 -77  416 -813  538  316   64  254  668   \n",
      "3  subj1_series3_3   81  203  343  183 -73  428 -766  467  283   66  217  499   \n",
      "4  subj1_series3_4   97  259  382  160 -61  441 -653  480  287   78  271  535   \n",
      "5  subj1_series3_5   79  259  328  154 -51  417 -682  465  297   85  321  634   \n",
      "6  subj1_series3_6   13  209  310   97 -56  374 -727  443  298  100  291  649   \n",
      "7  subj1_series3_7  -22  164  328  107 -72  421 -747  437  302  107  312  566   \n",
      "8  subj1_series3_8  -66  172  297  157 -79  452 -677  433  301  102  371  369   \n",
      "9  subj1_series3_9   32  262  300  172 -50  514 -537  422  299  106  476  426   \n",
      "\n",
      "    C3  Cz  TP9  CP5  CP1   P7   P3  \n",
      "0  237 -30 -285  204   48  407  230  \n",
      "1  240 -67 -336  237   37  448  215  \n",
      "2  220 -54 -223  251   45  691  250  \n",
      "3  196 -59 -286  225   15  335  217  \n",
      "4  193 -71 -287  190    0  145  190  \n",
      "5  217 -56 -248  207   17  204  197  \n",
      "6  201 -51 -227  224   29  327  230  \n",
      "7  222 -48 -183  213   50  363  234  \n",
      "8  225 -48 -236  203   49  349  227  \n",
      "9  210 -65 -318  200   32  334  219  \n"
     ]
    }
   ],
   "source": [
    "print test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Train_Labels_HandStart =  train_events['HandStart']\n",
    "Train_Labels_FirstDigitTouch =  train_events['FirstDigitTouch']\n",
    "Train_Labels_BothStartLoadPhase =  train_events['BothStartLoadPhase']\n",
    "Train_Labels_LiftOff =  train_events['LiftOff']\n",
    "Train_Labels_Replace =  train_events['Replace']\n",
    "Train_Labels_BothReleased =  train_events['BothReleased']\n",
    "# Train_Labels_Combined = train_events.HandStart.map(str) + ',' + train_events.FirstDigitTouch.map(str) + ',' + train_events.BothStartLoadPhase.map(str) + ',' + train_events.LiftOff.map(str) + ',' + train_events.Replace.map(str) + ',' + train_events.BothReleased.map(str)\n",
    "\n",
    "\n",
    "Train_Data = train_data.iloc[0:,1:] # select only column data\n",
    "\n",
    "\n",
    "Test_Labels_HandStart =  test_events['HandStart']\n",
    "Test_Labels_FirstDigitTouch =  test_events['FirstDigitTouch']\n",
    "Test_Labels_BothStartLoadPhase =  test_events['BothStartLoadPhase']\n",
    "Test_Labels_LiftOff =  test_events['LiftOff']\n",
    "Test_Labels_Replace =  test_events['Replace']\n",
    "Test_Labels_BothReleased =  test_events['BothReleased']\n",
    "\n",
    "\n",
    "Test_Data = test_data.iloc[0:,1:] # select only data columns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#bin the time \n",
    "def Bin_Time(num_rows,num_bins):\n",
    "    Bin_Size = num_rows/num_bins\n",
    "    Bins = np.zeros(shape=(num_rows,num_bins))\n",
    "    Bin_Min = 0\n",
    "    Bin_Max = Bin_Size\n",
    "    for i in range(0,num_bins):\n",
    "        Bins[Bin_Min:Bin_Max,i] = 1\n",
    "        Bin_Min = Bin_Min + Bin_Size\n",
    "        Bin_Max = Bin_Max + Bin_Size\n",
    "    return Bins\n",
    "\n",
    "\n",
    "##filters borrowed from Nihar. \n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "#run PCA and return the number of PCs that explain the given amount of variance. \n",
    "def extractFeatures_PCA(df,Test_df, PercentVarExplained):\n",
    "    data = df.as_matrix()\n",
    "    print len(data)\n",
    "    test_data = Test_df.as_matrix()\n",
    "    pca = PCA()\n",
    "    pca.fit(data)  \n",
    "    \n",
    "    Explained_Variance_Ratios = pca.explained_variance_ratio_\n",
    "    for i in range(1,len(Explained_Variance_Ratios)):\n",
    "        if sum(Explained_Variance_Ratios[0:i]) >= PercentVarExplained:\n",
    "                   NumPCs = i + 1 #add 1 since numpy array ranges are not inclusive\n",
    "                   break\n",
    "    PCA_Projections = pca.transform(data)[:,0:NumPCs]\n",
    "    PCA_Projections_Test = pca.transform(test_data)[:,0:NumPCs]\n",
    "    return PCA_Projections,PCA_Projections_Test\n",
    "\n",
    "\n",
    "\n",
    "#return rolling mean of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_mean(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_mean(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'mean' + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "\n",
    "#return rolling variance of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_var(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_var(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'var' + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "#return rolling min of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_min(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_min(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'min' + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "#return rolling max of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_max(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_max(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'max' + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "\n",
    "#return rolling skew of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_skew(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_skew(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'skew' + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "\n",
    "#return rolling skew of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_kurt(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_kurt(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'kurt' + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "\n",
    "#return rolling quantile of each column in a pandas dataframe with a given window and quantile. Returns df of same size. \n",
    "def df_rolling_quantile(df,window,quantile):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_quantile(df.iloc[0:,i],window,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:'Pct'+ quantile + \"_\" + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "#BE CAREFUL NOT TO SUPPLY TOO MANY COLUMNS TO THIS FUNCTION. Returns 2^N columns, where N = intitial columns. \n",
    "#return rolling pairwise correlation of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_corr(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        list_.append(pd.rolling_corr(df.iloc[0:,i],window,min_periods = 0))\n",
    "    return pd.concat(list_,1)\n",
    "\n",
    "\n",
    "\n",
    "#BE CAREFUL NOT TO SUPPLY TOO MANY COLUMNS TO THIS FUNCTION. Returns 2^N columns, where N = intitial columns. \n",
    "#return rolling pairwise correlation of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_cov(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        list_.append(rolling_cov(df.iloc[0:,i],window,min_periods = 0))\n",
    "    return pd.concat(list_,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Variables and what data will be in model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#Define Number of Bins with which to separate the data into features based on time progresses since test start. \n",
    "Num_Bins = 50\n",
    "\n",
    "Pct_Variance_Explained = .7\n",
    "PCA_Rolling_Window = 50 #window with which to use for rolling stats on PCs\n",
    "Raw_Data_Rolling_Window = 50 #window with which to use for rolling stats on raw data\n",
    "\n",
    "\n",
    "Train_Feature_List = ['Train_Data','RawData_Rolling_Skewness_Train','RawData_Rolling_Max_Train','RawData_Rolling_Min_Train']\n",
    "\n",
    "Test_Feature_List = [None]*len(Train_Feature_List)\n",
    "for i in range(0,len(Train_Feature_List)): \n",
    "    print i\n",
    "    Test_Feature_List[i] = re.sub('Train','Test', Train_Feature_List[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This chunk of code will us the Bin_Time function to bin each series into n number of features based on the length of the series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Train_Bin_List = []\n",
    "for i in range (0,len(Train_Array_Lengths)):\n",
    "    Train_Bin_List.append(Bin_Time(Train_Array_Lengths[i],Num_Bins)) # bin the time based on the sizes of each series. \n",
    "Train_Time_Bins = np.concatenate(Train_Bin_List, axis = 0)\n",
    "\n",
    "\n",
    "Test_Bin_List = []\n",
    "for i in range (0,len(Test_Array_Lengths)):\n",
    "    Test_Bin_List.append(Bin_Time(Test_Array_Lengths[i],Num_Bins)) # bin the time based on the sizes of each series. \n",
    "Test_Time_Bins = np.concatenate(Test_Bin_List, axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391450\n"
     ]
    }
   ],
   "source": [
    "Scale_Center = StandardScaler()\n",
    "Normalized_Train_Data = Scale_Center.fit_transform(np.array(Train_Data))\n",
    "Normalized_Test_Data = Scale_Center.fit_transform(np.array(Test_Data))\n",
    "\n",
    "\n",
    "df_Normalized_Train_Data = pd.DataFrame(Normalized_Train_Data)\n",
    "df_Normalized_Test_Data = pd.DataFrame(Normalized_Test_Data)\n",
    "\n",
    "PCA_Projections_Train, PCA_Projections_Test = extractFeatures_PCA(df_Normalized_Train_Data,df_Normalized_Test_Data,Pct_Variance_Explained)\n",
    "\n",
    "PCA_Rolling_Means_Train = df_rolling_mean(pd.DataFrame(PCA_Projections_Train),PCA_Rolling_Window)\n",
    "PCA_Rolling_Var_Train = df_rolling_var(pd.DataFrame(PCA_Projections_Train),PCA_Rolling_Window)\n",
    "PCA_Rolling_Skewness_Train = df_rolling_skew(pd.DataFrame(PCA_Projections_Train),PCA_Rolling_Window)\n",
    "PCA_Rolling_Kurtosis = df_rolling_kurt(pd.DataFrame(PCA_Projections_Train),PCA_Rolling_Window)\n",
    "PCA_Rolling_Min_Train = df_rolling_min(pd.DataFrame(PCA_Projections_Train),PCA_Rolling_Window)\n",
    "PCA_Rolling_Max_Train = df_rolling_max(pd.DataFrame(PCA_Projections_Train),PCA_Rolling_Window)\n",
    "\n",
    "\n",
    "PCA_Rolling_Means_Test = df_rolling_mean(pd.DataFrame(PCA_Projections_Test),PCA_Rolling_Window)\n",
    "PCA_Rolling_Var_Test = df_rolling_var(pd.DataFrame(PCA_Projections_Test),PCA_Rolling_Window)\n",
    "PCA_Rolling_Skewness_Test = df_rolling_skew(pd.DataFrame(PCA_Projections_Test),PCA_Rolling_Window)\n",
    "PCA_Rolling_Kurtosis_Test = df_rolling_kurt(pd.DataFrame(PCA_Projections_Test),PCA_Rolling_Window)\n",
    "PCA_Rolling_Min_Test = df_rolling_min(pd.DataFrame(PCA_Projections_Test),PCA_Rolling_Window)\n",
    "PCA_Rolling_Max_Test = df_rolling_max(pd.DataFrame(PCA_Projections_Test),PCA_Rolling_Window)\n",
    "\n",
    "Feature_Array_Train = np.concatenate((PCA_Projections_Train,PCA_Rolling_Means_Train,PCA_Rolling_Var_Train,PCA_Rolling_Min_Train,PCA_Rolling_Max_Train,Train_Time_Bins),axis=1)\n",
    "Feature_Array_Test = np.concatenate((PCA_Projections_Test,PCA_Rolling_Means_Test,PCA_Rolling_Var_Test,PCA_Rolling_Min_Test,PCA_Rolling_Max_Test,Test_Time_Bins),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "RawData_Rolling_Means_Train = df_rolling_mean(pd.DataFrame(Train_Data),Raw_Data_Rolling_Window)\n",
    "RawData_Rolling_Var_Train = df_rolling_var(pd.DataFrame(Train_Data),Raw_Data_Rolling_Window)\n",
    "RawData_Rolling_Skewness_Train = df_rolling_skew(pd.DataFrame(Train_Data),Raw_Data_Rolling_Window)\n",
    "RawData_Rolling_Kurtosis = df_rolling_kurt(pd.DataFrame(Train_Data),Raw_Data_Rolling_Window)\n",
    "RawData_Rolling_Min_Train = df_rolling_min(pd.DataFrame(Train_Data),Raw_Data_Rolling_Window)\n",
    "RawData_Rolling_Max_Train = df_rolling_max(pd.DataFrame(Train_Data),Raw_Data_Rolling_Window)\n",
    "\n",
    "\n",
    "RawData_Rolling_Means_Test = df_rolling_mean(pd.DataFrame(Test_Data),Raw_Data_Rolling_Window)\n",
    "RawData_Rolling_Var_Test = df_rolling_var(pd.DataFrame(Test_Data),Raw_Data_Rolling_Window)\n",
    "RawData_Rolling_Skewness_Test = df_rolling_skew(pd.DataFrame(Test_Data),Raw_Data_Rolling_Window)\n",
    "RawData_Rolling_Kurtosis_Test = df_rolling_kurt(pd.DataFrame(Test_Data),Raw_Data_Rolling_Window)\n",
    "RawData_Rolling_Min_Test = df_rolling_min(pd.DataFrame(Test_Data),Raw_Data_Rolling_Window)\n",
    "RawData_Rolling_Max_Test = df_rolling_max(pd.DataFrame(Test_Data),Raw_Data_Rolling_Window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Feature_Array_Train = np.concatenate([eval(n) for n in Train_Feature_List],axis=1)\n",
    "\n",
    "Feature_Array_Test = np.concatenate([eval(n) for n in Test_Feature_List],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "C_Value = 1\n",
    "penalty = 'l1'\n",
    "Convergence_tol = .01\n",
    "\n",
    "Logistic_Reg = LogisticRegression(C = C_Value, penalty = penalty,tol=Convergence_tol) \n",
    "\n",
    "Logistic_Reg.fit(Feature_Array_Train, Train_Labels_HandStart)\n",
    "HandStart_Predictions = Logistic_Reg.predict(Feature_Array_Test)\n",
    "\n",
    "\n",
    "# Logistic_Reg.fit(Feature_Array_Train, Train_Labels_FirstDigitTouch)\n",
    "# FirstDigitTouch_Predictions = Logistic_Reg.predict(Feature_Array_Test)\n",
    "\n",
    "# Logistic_Reg.fit(Feature_Array_Train, Train_Labels_BothStartLoadPhase)\n",
    "# BothStartLoadPhase_Predictions = Logistic_Reg.predict(Feature_Array_Test)\n",
    "\n",
    "# Logistic_Reg.fit(Feature_Array_Train, Train_Labels_LiftOff)\n",
    "# LiftOff_Predictions = Logistic_Reg.predict(Feature_Array_Test)\n",
    "\n",
    "# Logistic_Reg.fit(Feature_Array_Train, Train_Labels_Replace)\n",
    "# Replace_Predictions = Logistic_Reg.predict(Feature_Array_Test)\n",
    "\n",
    "# Logistic_Reg.fit(Feature_Array_Train, Train_Labels_BothReleased)\n",
    "# BothReleased_Predictions = Logistic_Reg.predict(Feature_Array_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print auc\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Test_Labels_HandStart, HandStart_Predictions, pos_label=1)\n",
    "print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, penalty='l1', random_state=None, tol=0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "LogReg = LogisticRegression(C = C_Value, penalty = penalty,tol=Convergence_tol) \n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfe = RFE(LogReg,10, step=2)\n",
    "rfe.fit(Feature_Array_Train, Train_Labels_HandStart)\n",
    "\n",
    "print rfe.estimator_ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the accuracy of the model. The first part looks at the overall accuracy when all 6 events are combined into one array. The accuracy is then broken down by the 6 parts. All accuracies are presented as the percent improvement over random. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Different Models\n",
    "\n",
    "##Logistic Regession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#set parameters for Logistic Regression\n",
    "#Setting them here will allow the optimization of the parameters. We saw in project 2 how much the C-value can affect the results. \n",
    "C_Value = 1\n",
    "penalty = 'l1'\n",
    "Convergence_tol = .01\n",
    "\n",
    "#Create a function that trains and runs a logistic regression model. Then prints and returns the AUC score\n",
    "def predictCategory_LogReg(train_data, train_label, test_data, test_label, Category, C_Value,penalty, Convergence_tol):\n",
    "    Logistic_Reg = LogisticRegression(C = C_Value, penalty = penalty,tol=Convergence_tol)    \n",
    "    Logistic_Reg.fit(train_data, train_label)\n",
    "    print(Category, \" Score =\", Logistic_Reg.score(test_data, test_label))\n",
    "\n",
    "    prob = Logistic_Reg.predict_proba(test_data)\n",
    "    print(Category, \"AUC\", roc_auc_score(test_label, prob[:,1]))\n",
    "\n",
    "    #FPR, TPR, thresholds = roc_curve(Test_Labels_HandStart, prob[:,1])\n",
    "    return roc_auc_score(test_label, prob[:,1])\n",
    "    \n",
    "AUC_HandStart = predictCategory_LogReg(Feature_Array_Train,Train_Labels_HandStart,Feature_Array_Test,Test_Labels_HandStart, 'HandStart', C_Value,penalty, Convergence_tol)\n",
    "AUC_FirstDigitTouch = predictCategory_LogReg(Feature_Array_Train,Train_Labels_FirstDigitTouch,Feature_Array_Test,Test_Labels_FirstDigitTouch, 'FirstDigitTouch', C_Value,penalty, Convergence_tol)\n",
    "AUC_BothStartLoadPhase = predictCategory_LogReg(Feature_Array_Train,Train_Labels_BothStartLoadPhase,Feature_Array_Test,Test_Labels_BothStartLoadPhase, 'BothStartLoadPhase', C_Value,penalty, Convergence_tol)\n",
    "AUC_LiftOff = predictCategory_LogReg(Feature_Array_Train,Train_Labels_LiftOff,Feature_Array_Test,Test_Labels_LiftOff, 'LiftOff', C_Value,penalty, Convergence_tol)\n",
    "AUC_Replace = predictCategory_LogReg(Feature_Array_Train,Train_Labels_Replace,Feature_Array_Test,Test_Labels_Replace, 'Replace', C_Value,penalty, Convergence_tol)\n",
    "AUC_BothReleased = predictCategory_LogReg(Feature_Array_Train,Train_Labels_BothReleased,Feature_Array_Test,Test_Labels_BothReleased, 'BothReleased', C_Value,penalty, Convergence_tol)\n",
    "\n",
    "print \"Overall Logistic Regression Score = \", np.mean((AUC_HandStart, AUC_FirstDigitTouch,AUC_BothStartLoadPhase,AUC_LiftOff,AUC_Replace,AUC_BothReleased))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "Start_Time = time.time()\n",
    "\n",
    "# Define an output queue\n",
    "output = mp.Queue()\n",
    "\n",
    "def Log_Reg_HandStart(output):\n",
    "    AUC = predictCategory_LogReg(Feature_Array_Train,Train_Labels_HandStart,Feature_Array_Test,Test_Labels_HandStart, 'HandStart', C_Value,penalty, Convergence_tol)\n",
    "    output.put(AUC)\n",
    "    \n",
    "def Log_Reg_FirstDigitTouch(output):    \n",
    "    AUC = predictCategory_LogReg(Feature_Array_Train,Train_Labels_FirstDigitTouch,Feature_Array_Test,Test_Labels_FirstDigitTouch, 'FirstDigitTouch', C_Value,penalty, Convergence_tol)\n",
    "    output.put(AUC)\n",
    "    \n",
    "def Log_Reg_BothStartLoadPhase(output):       \n",
    "    AUC = predictCategory_LogReg(Feature_Array_Train,Train_Labels_BothStartLoadPhase,Feature_Array_Test,Test_Labels_BothStartLoadPhase, 'BothStartLoadPhase', C_Value,penalty, Convergence_tol)\n",
    "    output.put(AUC)\n",
    "    \n",
    "def Log_Reg_LiftOff(output):       \n",
    "    AUC = predictCategory_LogReg(Feature_Array_Train,Train_Labels_LiftOff,Feature_Array_Test,Test_Labels_LiftOff, 'LiftOff', C_Value,penalty, Convergence_tol)\n",
    "    output.put(AUC)\n",
    "    \n",
    "def Log_Reg_Replace(output):     \n",
    "    AUC = predictCategory_LogReg(Feature_Array_Train,Train_Labels_Replace,Feature_Array_Test,Test_Labels_Replace, 'Replace', C_Value,penalty, Convergence_tol)\n",
    "    output.put(AUC)\n",
    "    \n",
    "def Log_Reg_BothReleased(output):    \n",
    "    AUC = predictCategory_LogReg(Feature_Array_Train,Train_Labels_BothReleased,Feature_Array_Test,Test_Labels_BothReleased, 'BothReleased', C_Value,penalty, Convergence_tol)\n",
    "    output.put(AUC)\n",
    "    \n",
    "# Setup a list of processes that we want to run\n",
    "processes = [mp.Process(target=Log_Reg_HandStart)\n",
    "            ,mp.Process(target=Log_Reg_FirstDigitTouch)\n",
    "            ,mp.Process(target=Log_Reg_BothStartLoadPhase)\n",
    "            ,mp.Process(target=Log_Reg_LiftOff)\n",
    "            ,mp.Process(target=Log_Reg_Replace)\n",
    "            ,mp.Process(target=Log_Reg_BothReleased)]\n",
    "\n",
    "print processes\n",
    "# Run processes\n",
    "for p in processes:\n",
    "    p.start()\n",
    " \n",
    "\n",
    "\n",
    "for p in processes:\n",
    "    p.join()\n",
    " \n",
    "# Get process results from the output queue\n",
    "results = [output.get() for p in processes]\n",
    "    \n",
    "print \"Overall Logistic Regression Score = \", np.mean((AUC_HandStart, AUC_FirstDigitTouch,AUC_BothStartLoadPhase,AUC_LiftOff,AUC_Replace,AUC_BothReleased))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print \"IFFFFF\"\n",
    "    p = Process(target=Log_Reg_Summary)\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "# AUC_HandStart = predictCategory_LogReg(Feature_Array_Train,Train_Labels_HandStart,Feature_Array_Test,Test_Labels_HandStart, 'HandStart', C_Value,penalty, Convergence_tol)\n",
    "# AUC_FirstDigitTouch = predictCategory_LogReg(Feature_Array_Train,Train_Labels_FirstDigitTouch,Feature_Array_Test,Test_Labels_FirstDigitTouch, 'FirstDigitTouch', C_Value,penalty, Convergence_tol)\n",
    "# AUC_BothStartLoadPhase = predictCategory_LogReg(Feature_Array_Train,Train_Labels_BothStartLoadPhase,Feature_Array_Test,Test_Labels_BothStartLoadPhase, 'BothStartLoadPhase', C_Value,penalty, Convergence_tol)\n",
    "\n",
    "print time.time()-Start_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('HandStart', ' Score =', 0.98028619482202428)\n",
      "('HandStart', 'AUC', 0.73293521880342571)\n",
      "('BothStartLoadPhase', ' Score =', 0.98018509838521417)\n",
      "('BothStartLoadPhase', 'AUC', 0.71070132577101419)\n",
      "('BothStartLoadPhase', ' Score =', 0.98019888426296098)\n",
      "('BothStartLoadPhase', 'AUC', 0.71155041096067695)\n",
      "None\n",
      "43.861000061\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from multiprocessing import Process\n",
    "    \n",
    "Start_Time = time.time()\n",
    "def runInParallel(*fns):\n",
    "    proc = []\n",
    "    for fn in fns:\n",
    "        p = Process(target=fn)\n",
    "        p.start()\n",
    "        #proc.append(p)\n",
    "    #for p in proc:\n",
    "        #p.join()\n",
    "\n",
    "output = runInParallel(predictCategory_LogReg(Feature_Array_Train,Train_Labels_HandStart,Feature_Array_Test,Test_Labels_HandStart, 'HandStart', C_Value,penalty, Convergence_tol)\n",
    ", predictCategory_LogReg(Feature_Array_Train,Train_Labels_BothStartLoadPhase,Feature_Array_Test,Test_Labels_BothStartLoadPhase, 'BothStartLoadPhase', C_Value,penalty, Convergence_tol)\n",
    ", predictCategory_LogReg(Feature_Array_Train,Train_Labels_BothStartLoadPhase,Feature_Array_Test,Test_Labels_BothStartLoadPhase, 'BothStartLoadPhase', C_Value,penalty, Convergence_tol)\n",
    ")\n",
    "print output\n",
    "print time.time()-Start_Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is set up to get started. It has not been tested. MM 08/04/2015 11:30 A.M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set parameters for SVM\n",
    "#Setting them here will allow the optimization of the parameters. We saw in project 2 how much the C-value can affect the results. \n",
    "C_Value = 1\n",
    "kernel = 'rbf'\n",
    "degree = 3\n",
    "\n",
    "#Create a function that trains and runs a model. Then prints and returns the AUC score\n",
    "def predictCategory_SVM(train_data, train_label, test_data, test_label, Category, C_Value,kernel, degree):\n",
    "    SVM = SVC(C = C_Value, kernel = kernel,degree=degree)    \n",
    "    SVC.fit(train_data, train_label)\n",
    "\n",
    "    prob = SVC.predict_proba(test_data)\n",
    "    print(Category, \"AUC\", roc_auc_score(test_label, prob[:,1]))\n",
    "\n",
    "    #FPR, TPR, thresholds = roc_curve(Test_Labels_HandStart, prob[:,1])\n",
    "    return roc_auc_score(test_label, prob[:,1])\n",
    "    \n",
    "AUC_HandStart = predictCategory_SVM(Feature_Array_Train,Train_Labels_HandStart,Feature_Array_Test,Test_Labels_HandStart, 'HandStart', Category, C_Value,kernel, degree)\n",
    "AUC_FirstDigitTouch = predictCategory_SVM(Feature_Array_Train,Train_Labels_FirstDigitTouch,Feature_Array_Test,Test_Labels_FirstDigitTouch, 'FirstDigitTouch', Category, C_Value,kernel, degree)\n",
    "AUC_BothStartLoadPhase = predictCategory_SVM(Feature_Array_Train,Train_Labels_BothStartLoadPhase,Feature_Array_Test,Test_Labels_BothStartLoadPhase, 'BothStartLoadPhase', Category, C_Value,kernel, degree)\n",
    "AUC_LiftOff = predictCategory_SVM(Feature_Array_Train,Train_Labels_LiftOff,Feature_Array_Test,Test_Labels_LiftOff, 'LiftOff', Category, C_Value,kernel, degree)\n",
    "AUC_Replace = predictCategory_SVM(Feature_Array_Train,Train_Labels_Replace,Feature_Array_Test,Test_Labels_Replace, 'Replace', Category, C_Value,kernel, degree)\n",
    "AUC_BothReleased = predictCategory_SVM(Feature_Array_Train,Train_Labels_BothReleased,Feature_Array_Test,Test_Labels_BothReleased, 'BothReleased', Category, C_Value,kernel, degree\n",
    "\n",
    "\n",
    "print \"Overall SVM Score = \", np.mean(AUC_HandStart, AUC_FirstDigitTouch,AUC_BothStartLoadPhase,AUC_LiftOff,AUC_Replace,AUC_BothReleased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set parameters for Neural Network model\n",
    "#Setting them here will allow the optimization of the parameters. We saw in project 2 how much the C-value can affect the results. \n",
    "n_components = 10\n",
    "learning_rate = .1\n",
    "batch_size = 20000\n",
    "n_iter =1\n",
    "\n",
    "\n",
    "#Create a function that trains and runs a model. Then prints and returns the AUC score\n",
    "def predictCategory_Neural_Network(train_data, train_label, test_data, test_label, Category, C_Value,kernel, degree):\n",
    "    SVM = SVC(C = C_Value, kernel = kernel,degree=degree)    \n",
    "    SVC.fit(train_data, train_label)\n",
    "\n",
    "    prob = SVC.predict_proba(test_data)\n",
    "    print(Category, \"AUC\", roc_auc_score(test_label, prob[:,1]))\n",
    "\n",
    "    #FPR, TPR, thresholds = roc_curve(Test_Labels_HandStart, prob[:,1])\n",
    "    return roc_auc_score(test_label, prob[:,1])\n",
    "    \n",
    "AUC_HandStart = predictCategory_Neural_Network(Feature_Array_Train,Train_Labels_HandStart,Feature_Array_Test,Test_Labels_HandStart, 'HandStart', Category, C_Value,kernel, degree)\n",
    "AUC_FirstDigitTouch = predictCategory_Neural_Network(Feature_Array_Train,Train_Labels_FirstDigitTouch,Feature_Array_Test,Test_Labels_FirstDigitTouch, 'FirstDigitTouch', Category, C_Value,kernel, degree)\n",
    "AUC_BothStartLoadPhase = predictCategory_Neural_Network(Feature_Array_Train,Train_Labels_BothStartLoadPhase,Feature_Array_Test,Test_Labels_BothStartLoadPhase, 'BothStartLoadPhase', Category, C_Value,kernel, degree)\n",
    "AUC_LiftOff = predictCategory_Neural_Network(Feature_Array_Train,Train_Labels_LiftOff,Feature_Array_Test,Test_Labels_LiftOff, 'LiftOff', Category, C_Value,kernel, degree)\n",
    "AUC_Replace = predictCategory_Neural_Network(Feature_Array_Train,Train_Labels_Replace,Feature_Array_Test,Test_Labels_Replace, 'Replace', Category, C_Value,kernel, degree)\n",
    "AUC_BothReleased = predictCategory_Neural_Network(Feature_Array_Train,Train_Labels_BothReleased,Feature_Array_Test,Test_Labels_BothReleased, 'BothReleased', Category, C_Value,kernel, degree\n",
    "\n",
    "\n",
    "print \"Overall SVM Score = \", np.mean(AUC_HandStart, AUC_FirstDigitTouch,AUC_BothStartLoadPhase,AUC_LiftOff,AUC_Replace,AUC_BothReleased)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
